{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Самое главное это формулирование гипотез и их проверка. При чем не только стат проверка и стат гипотезы.  \n",
    ">Когда у насть есть Цель, то у нас уже могут появиться гипотезы. Нужно их записать. Подумать какие гипотезы нужно проверить, чтобы ответить на поставленную задачу.   Тут мы не думаем есть ли зависимость или нет. Тут мы формулируем все возможные гипотезы, которые связаны с целью и их все нужно будет првоерить.  \n",
    ">Далее во время анализа графиков, у нас появяться дополнительные гипотезы, когда мы уже будем изучать как взаимодействуют разные переменные.  \n",
    ">Процесс с графиками следующий - мы смотрим на график, на котором например 2 категориальные переменные и доли между ними (нормированные).  \n",
    ">Если мы видим, что влияние есть, то есть есть различия в долях, то мы формулируем гипотезу. А вот на графиках, мы ищем возможные зависимости,  \n",
    ">на основе которых можно выдвинуть гипотезу. Мы не можем на все пары категорий выдвигать гипотезы. Их очень много.  \n",
    ">Для этого мы и строим графики, чтобы заметить потенциальные зависимости.  \n",
    ">То есть мы формулируем гипотезу только для тех случаев, где по графику видно, что зависимость возможна.  \n",
    ">Лучше гипотезу выдвигать как в статистике, то есть нулевая гипотеза, что влияния нет. Даже несмотря на то, что мы на графике заметили возможное влияние.  \n",
    ">И часто у нас будет не 2 значения в категории, то есть стат тест будет показывать есть ли действительно хотя бы одно различие в парах.  \n",
    ">И далее мы уже сделаем например тест тьюки. И вот тут нужно правильно потом делать выводы. \n",
    ">Например, у нас график долей уровня образования и семейного положения. Мы выдвигаем гипотезу.  \n",
    ">Гипотеза: Уровень образования не влияет на семейное полжение.\n",
    ">Тут важно правильно расставить порядок, чтобы было логично, так как например, образование люди получают раньше чем созадют семью.  \n",
    ">Таким образом в наблюдениях под графиками у нас будут сами наблюдения и выдвинутые гипотезы.  \n",
    ">И далее мы собираем все эти гипотезы и в разделе проверки гипотез, мы уже проверяем стат тестами наши гипотезы, которые можно проверить.  \n",
    ">И после проверки, формулируем вывод, основываясь как на графике, так и на результате стат теста.  \n",
    ">В результате в конце отчета у нас список гипотез с результатами и выводы.  \n",
    ">А в выводы мы превращаем гипотезы в выводы, то есть переводим на человеческий язык с языка статистики, делаем предложение более понятным, чтобы можно было  \n",
    ">принять решение на основе этого вывода.  \n",
    ">Не забываем, что между 2 числовыми переменными тоже выдвигаем гипоетзы, если на матрице корреляции видим коэффициент корреляции больше 0.6  \n",
    ">И Аналогично для сравнения числовой и категориальных переменных. Также мы сравниваем средние и если видим, что влияение есть,  \n",
    ">то также выдвигаем гипотезы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Исследование надёжности заёмщиков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Автор:**  \n",
    "Григорьев Павел   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Описание проекта:**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Заказчик — кредитный отдел банка. Нужно разобраться, влияет ли семейное положение и количество детей клиента на факт погашения кредита в срок. Входные данные от банка — статистика о платёжеспособности клиентов.  \n",
    ">Результаты исследования будут учтены при построении модели кредитного скоринга — специальной системы, которая оценивает способность потенциального заёмщика вернуть кредит банку.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\n",
    "**Цель:**  \n",
    ">Составить рекомендации для кредитного отдела банка, которые будут учтены при построении модели кредитного скоринга.  \n",
    ">Определить влияет ли семейное положение и количество детей клиента на факт погашения кредита в срок.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Источники данных:**  \n",
    ">Статистика о платёжеспособности клиентов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Условия проведения анализа днных:**  \n",
    ">указываем временной интервал выборки  \n",
    ">Например, 'для анализ будут использоваться данные за год с 1 июня 2017 по 31 мая 2018 года'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Главные выводы:**   \n",
    "тут помещаем самое главное из общего вывода, примерно до полустраницы, чтобы не было сильно много и при этом указать все главные выводы\n",
    "Будет идеально, елси выводы на похожие темы будут рядом, то есть елси мы имеем несколько выводов о доходе, то лушче поместить их рядом\n",
    "- Женщины чаще возвращают кредит, чем мужчины.\n",
    "- Долги присутствуют у людей с разным доходом.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Аномалии и особенности в данных:**\n",
    "- В датафрейме есть строки дубликаты. 54 строки. Меньше 1 % от всего датафрейма.  \n",
    "- В столбце с количеством детей есть отрицательные значения. 47 штук. Меньше 1 процента от всего датафрейма. Также есть клиенты с 20 детьми. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Рекомендации:**  \n",
    "- Добавить контроль данных, чтобы не дублировались значения с разными регистрами в колонке с образованием.\n",
    "- Добавить уникальный идентификатор клиента, чтобы избежать дублирования строк."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Оглавление** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "(опционально, зависит от того есть ли оглавление по умолчанию, но лучше сделать скрываемое, так как не везде будет автоматическое):  \n",
    "создаем оглавление с гиперссылками  \n",
    "Тут важно давать развернутые названия разделам в работе, но и не сильно большие (пиши - сокращай).  \n",
    "Все таки это название главы и оно должно быть не более 5-7 слов. Некоторые могут быть длиннее, если сильно нужно,  \n",
    "но основная часть названий разделов и глав долны быть достаточно кратикими.   \n",
    "Чтобы понять длинные ли заголовки - смотрим на оглавление и думаем не сильно ли шировкие строчки.  \n",
    "Чтобы в оглавление хорошо читалось и было понятно про что каждый раздел и глава и чтобы  \n",
    "можно было прочитать, понять и перейти к разделу. Нельзя писать сильно кратко, так как люди не знакомы с работой и им нужно более развернутые  \n",
    "названия глав, чтобы понимать о чем там будет идти речь  \n",
    "Оглавление делаем со сворачивающимися списками, то есть каждую главу можно свернуть, можно развернуть и пеерейти на уровень ниже,  \n",
    "как в сводных таблицах экселя, так удобнее, так как места занимает мало, если скрыть все подразделы, а если нужно, то раскроют  \n",
    "В каждом блоке сделать гиперссылку 'к содержанию', чтобы можно было вернуться к содержанию,  \n",
    "но тут важно, чтобы на одной странице не было больше 1 такой ссылки.   \n",
    "Заголовки разделов и глав не нужно писать в стиле 'посчитаем, выясним, исследуем и подобное', так как названия глав и разделов это более официальные  \n",
    "названия. Нужно более формально их называть.  \n",
    "Название главы или раздела должно нести в себе основной смысл этого раздела или главы, так и нужно называть.  \n",
    "1. Описание данных\n",
    "2. Предобработка данных\n",
    "3. Расчет метрик\n",
    "    3.1 Продуктовые метрики\n",
    "        3.1.1 Расчет MAU, DAU, WAU\n",
    "        3.1.2 Рачет ASL\n",
    "4. Подведение итогов и регкомендации       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, Layout\n",
    "from IPython.display import display, display_html, display_markdown\n",
    "import my_module\n",
    "import importlib\n",
    "import re\n",
    "import itertools\n",
    "from pymystem3 import Mystem\n",
    "importlib.reload(my_module)\n",
    "import chart_studio\n",
    "import chart_studio.plotly as py\n",
    "sns.set(style=\"white\")\n",
    "from termcolor import colored\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.api as stm\n",
    "import httpimport\n",
    "# with httpimport.remote_repo('http://my-codes.example.com/python_packages'):\n",
    "#     import package1\n",
    "\n",
    "# chart_studio.tools.set_credentials_file(username=\"bestorlov1992\", api_key=\"TOnnvREBwfkILt9ABEr5\")\n",
    "# # from jupyter to chart studio\n",
    "# py.plot(fig, filename = \"plot name\", auto_open = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание и изучение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание данных\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- children - количество детей в семье\n",
    ">- days_employed - общий трудовой стаж в днях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">сначала грузим 5-10 строк (указываем в `pd.read_csv` `nrow`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Изучаем данные и определяемся с типами, потом их указваем в `pd.read`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Важно привести названия столбцов к нижнему регистру, убрать пробелы (заменить их на _),  \n",
    ">так как в том же merge могту быть проблемы, если это не сделать и вообще будет удобнее работать "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если после попытки привести тип к нужному, мы получили ошибку,  \n",
    "то обязательно изучаем эти строки. Именно строки, не только сами занчения, которые не можем преобразовать.  \n",
    "Часто бывает у нас в ругих столбцах есть категория например, которая портит все,  \n",
    "и при этом это выброс может быть.  Поэтому обязательно првоеряем строки, в которых строки не преобразуются в нужный тип.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Очень важно писать код, чтобы не учитывался порядок столбцов. Чтобы если порядок изменится, то наш скрипт будет работать верно.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Также важно категориальные столбцы привести к типу `category` и для столбцов, которые имеют малый диапазон значений заменить на меньший тип,  \n",
    "например на `int8`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Делаем названия колонок краткими, но понятными.  \n",
    "Если у нас непонятное название типа, dob_years, то меняем его на  более понятное, например, age. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Изучение переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>children</th>\n",
       "      <th>days_employed</th>\n",
       "      <th>dob_years</th>\n",
       "      <th>education</th>\n",
       "      <th>education_id</th>\n",
       "      <th>family_status</th>\n",
       "      <th>family_status_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>income_type</th>\n",
       "      <th>debt</th>\n",
       "      <th>total_income</th>\n",
       "      <th>purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4042</th>\n",
       "      <td>1</td>\n",
       "      <td>-2885.142188</td>\n",
       "      <td>50</td>\n",
       "      <td>среднее</td>\n",
       "      <td>1</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>0</td>\n",
       "      <td>80236.028323</td>\n",
       "      <td>приобретение автомобиля</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19177</th>\n",
       "      <td>2</td>\n",
       "      <td>-1803.080913</td>\n",
       "      <td>36</td>\n",
       "      <td>Среднее</td>\n",
       "      <td>1</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>0</td>\n",
       "      <td>163292.220004</td>\n",
       "      <td>строительство собственной недвижимости</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7372</th>\n",
       "      <td>1</td>\n",
       "      <td>-305.540665</td>\n",
       "      <td>27</td>\n",
       "      <td>СРЕДНЕЕ</td>\n",
       "      <td>1</td>\n",
       "      <td>гражданский брак</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>0</td>\n",
       "      <td>69799.488812</td>\n",
       "      <td>ремонт жилью</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16245</th>\n",
       "      <td>1</td>\n",
       "      <td>-1593.946336</td>\n",
       "      <td>50</td>\n",
       "      <td>среднее</td>\n",
       "      <td>1</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>1</td>\n",
       "      <td>107486.332934</td>\n",
       "      <td>на покупку подержанного автомобиля</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11563</th>\n",
       "      <td>0</td>\n",
       "      <td>-1025.402943</td>\n",
       "      <td>64</td>\n",
       "      <td>высшее</td>\n",
       "      <td>0</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>госслужащий</td>\n",
       "      <td>0</td>\n",
       "      <td>706401.475790</td>\n",
       "      <td>профильное образование</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       children  days_employed  dob_years education  education_id  \\\n",
       "4042          1   -2885.142188         50   среднее             1   \n",
       "19177         2   -1803.080913         36   Среднее             1   \n",
       "7372          1    -305.540665         27   СРЕДНЕЕ             1   \n",
       "16245         1   -1593.946336         50   среднее             1   \n",
       "11563         0   -1025.402943         64    высшее             0   \n",
       "\n",
       "          family_status  family_status_id gender  income_type  debt  \\\n",
       "4042    женат / замужем                 0      F    сотрудник     0   \n",
       "19177   женат / замужем                 0      F    сотрудник     0   \n",
       "7372   гражданский брак                 1      F    сотрудник     0   \n",
       "16245   женат / замужем                 0      F    сотрудник     1   \n",
       "11563   женат / замужем                 0      M  госслужащий     0   \n",
       "\n",
       "        total_income                                 purpose  \n",
       "4042    80236.028323                 приобретение автомобиля  \n",
       "19177  163292.220004  строительство собственной недвижимости  \n",
       "7372    69799.488812                            ремонт жилью  \n",
       "16245  107486.332934      на покупку подержанного автомобиля  \n",
       "11563  706401.475790                  профильное образование  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype = {'education': 'category', 'family_status': 'category', 'gender': 'category', 'income_type': 'category'}\n",
    "df = pd.read_csv('https://code.s3.yandex.net/datasets/data.csv', dtype=dtype)\n",
    "df.sample(5, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Сразу меняем название колонок, которые имеют непонятные названия.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'dob_years': 'age'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Изменяем значения в столбцах на более удобные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.debt = df.debt.apply(lambda x: 'есть' if x == '1' else 'нет').astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем метод `my_info` или `my_info_gen` для вывода информации о датасете и колонках"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ВАЖНО  \n",
    "если заметил выброс в колонке, то записываем не только в наблюдения.  \n",
    "Задача все выбросы записать и вставить в блок где будем обрабатывать выбросы и в блок изучения выбросов.  \n",
    "Это очень важно, так как потом можно забыть, что в какой-то колонке было некорректное значение.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следим за аномалиями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для категориальных переменных записываем сколько элементов в каждой группе этой категориальной переменной.  \n",
    "Важное из этого распределения количества внутри групп берем в выводы, и также сохраняем количество элементов,  \n",
    "чтобы по ходу анализа можно было посмоттреть сколько элементов в определенной группе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = my_module.my_info_gen(df)\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Наблюдения:**\n",
    "- В колонке цель кредита пропуско нет  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">ВАЖНО   \n",
    ">Если увидели, что у нас в категориальной переменной одни и те же значения, но записанные с большой и с маленькой буквы, например,  \n",
    ">или другие проблемы с написанием одно и того же слова, что приводит к увеличению значений в категории.   \n",
    ">То нужно сразу это убирать, так как дальнейший анализ будет страдать.  \n",
    ">Для дальнейшего анализа срауз приведем колонку education к нижнему регистру и удалим лишние пробелы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Для дальнейшего анализа срауз приведем колонку education к нижнему регистру и удалим лишние пробелы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.education = my_module.normalize_string_series(df.education)\n",
    "df.education.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">сделать предположения, почему могло так произойти, выдвигаем гипотезы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">придумать способы проверки выдвинутых гипотез и записать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">если у нас по оси x время, то проанализировать сезонность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">подумать а так и должно было получиться, основываясь на понимании физики параметра  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">зафиксировать возможные рекомендации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Для гистограмм, нужно понять почему именно такое распределение метрики.  \n",
    ">Совпадет это с логикой этой метрики. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Также когда строим гистограммы и вайолин плот, то не просто фиксируем, что есть тяжелые хвосты, разброс между квартилями такой-то.  \n",
    ">А думаем почему так, пытаемся связать это с физикой параметра. Должно быть физическое объяснение всех аномалий.  \n",
    ">Если объяснения нет, то возможно это инсайт.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Важно убедиться, что у нас есть данные на все источники, которые заявлены. Например, мы изучаем источники трафика и у нас они в разных таблицах.  \n",
    ">Нужно убедиться, что во всех таблицах есть все источники, и проверить нет ли аномалий, возможно какой-то сильно выбивается или какого-то вообще где-то нет.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">И очень важно сверить, что периоды в разных таблицах (если у нас больше одной таблицы) совпадают.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Важно проверить соответствуют ли временной период данных тому, который заявлен в задании,  \n",
    ">определиться что будем делать с неполными периодами.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Вообще, когда у нас несколько таблиц и там есть категориальные переменные или время, то  \n",
    ">мы должны взять уникальные значения категориальных переменных из каждой таблицы (одниаковые переменные) и сравнить.  \n",
    ">Количество уникальных должно совпадать, иначе нужно разбираться  \n",
    ">И с верменем как минимум мин и макс даты должны совпадать до дня, а лушше до минуты часа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Очень важно, если у нас есть стартовая дата чего-то и конечная, то обязательно нужно проверить,  \n",
    ">нет ли у нас записей, где конечная дата меньше стартовой.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Важная проверка, если у нас есть категории и даты, то сгруппировать по категориями и \n",
    ">вывести количество занчений, минимальную и максимальную дату  \n",
    ">Таким образом мы сразу поймем распределение в категории и  \n",
    ">увидем какие временные интервалы у каждой категории  \n",
    ">Если у нас все категории должны быть в один день, то мы поймем нет ли багов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Вообще очень важно смотреть не только на аномалии в значениях, но и аномалии в категориальных переменных.  \n",
    ">А тут аномалией будет отстутствие какого-то значения, хотя в описании или поставновке задачи оно есть.  \n",
    ">Также совпадение количества значений категориальных переменных в разных таблицах.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Внимательно посмотреть на столбцы, если есть столбцы, в которых могут быть потенциальные анамали, то проверить их.  \n",
    ">Например, есть столбец возрасти стаж работы, проверить, что возраст больше стажа.  \n",
    ">И подобные случаи.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Проверка на нарушения уникальности   \n",
    ">Убедить, что столбцы, значения в которых не должны повторяться и должны быть уникальными, такие в действительности.    \n",
    ">Смотрим на результат функции `my_info`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Проверка на ошибки целостности  \n",
    ">Если у нас есть столбцы, в которых значения должны совпдаать попарно, то проверяем на это  \n",
    ">`get_non_matching_rows`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.get_non_matching_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Проверка условий  \n",
    ">Проверьте, что данные в датафрейме удовлетворяют определенным условиям, таким как \"возраст > 18\" или \"страна == 'Россия'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Изучение дубликатов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Не забываем про ИИ.  \n",
    ">Пишем список столбцов (именно что они значат, то есть образование, пол и прочее), говорим, что есть дубли.  \n",
    ">И просим предложить причины этих дублей. Если видим важное, то используем для рекомендаций, выводов и замены дублей в предобработке.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Проверяем на дубли  \n",
    "- Важно помнить, что если у нас есть id и название товара, то названия товара все равно нужно проверить на дубли,  \n",
    ">возможно у нас 2 ай ди с одним названием. \n",
    "- Также важно в каждой отдельной колонке проверить дубли и если их много, то посмотреть на соседние колонки, что там происходит\n",
    "- Дубликаты часто носят скрытый характер.  \n",
    ">То есть это могут быть поля, которые записаны  по разному, но относятся к одному и тому же.  \n",
    ">Поэтому важно, если у нас категориальный признак, изучить нет ли повторящихся категорий, которые записаны немного по разному.  \n",
    ">Так как это создает шум, мы по сути имеем две разные категории, но на самом деле это одна. Нужно собрать их в одну.  \n",
    "- И очень важно, если мы не подтвердили, что это действительно дубликат (например у нас нет ай ди клиента и мы не смогли выяснить один и тот же ли это человек),  \n",
    ">то нужно аккуратно удалять их. Но и оставлять много дублей плохо, так как они вносят шумы и искажения.  \n",
    "- Помним, что наличие дубликата не говорит точно, что это дубль, возможно у нас нет ещё колонок, котоыре бы детализировали и разделили эти дубли.  \n",
    ">Поэтому тут могут быть рекомендации, чтобы добавли в фрейм доп колонки, которые помогут убрать дубли (либо сам ищешь ещё поля)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Когда смотрим на дубли, то нужно ответить на вопрос так и должно быть, это нормально, что дубли в этих колонках.   \n",
    ">Например у нас дубли во всех строках таблицы, нам нужно понять это может быть или этого не может быть, и нужно разбираться.   \n",
    ">Аналогично когда смотрим колонки по 2, 3 и так далее, то самое главное, ответить на вопрос дубли могут быть в этих колонках.   \n",
    ">Также когда разбиваем по категориям, задаем себе вопрос так могли распреедлеиться дубли.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">`check_duplicated`  \n",
    ">`check_duplicated_combinations_gen`  \n",
    ">В первую функцию можно передавать весь датафрейм и можно выбирать нужные столбцы для проверки на дубли и передавать их.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если мы нашли колонки в которых дубликатов не должно быть, то нужно изучить эти дубликаты по категориальным переменным в нашем датафрейме  \n",
    ">`analys_by_category_gen`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Наблюдения:**\n",
    "- Особых перекосов в сторону определенного значения в категории не наблюдается"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Идем по порядку с помощью next(gen)  \n",
    ">если в выводе нет ничего интересного, то  выше помещаем ячейку с таким содержимым\n",
    ">%%capture  \n",
    ">next(gen)  \n",
    ">снова выполняем next(gen), если снова ничего интересного то, к ячейке выше добавляем next(gen)  будет так  \n",
    ">%%capture  \n",
    ">next(gen);next(gen)  \n",
    ">и так далее, пока не появится важная ячейка  \n",
    ">далее оставляем эту важную ячейку и снова повторяем с первого пункта,  \n",
    ">в итоге между ячейками с нужным выводом будут ячейки с запрещенным выводом и можно будет прогонять ноутбук весь целиком и выводы будут в нужнфх местах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Посмотрим на дубли во всем датафрейме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.check_duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Посмотрим сколько у нас дублей в каждой колонке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_duplicated = my_module.find_columns_with_duplicates(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Посмотрим на строки датафрейма с дублями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1_duplicated = series_duplicated['col1']\n",
    "col2_duplicated = series_duplicated['col2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1_duplicated.head()\n",
    "col2_duplicated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.check_duplicated_combinations_gen()\n",
    "my_module.analys_by_category_gen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Важно на дубли проверить и отдельные строки и целиком таблицу и подумать какие группы столбцов могут дать дубли и на это тоже проверить.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если в дублях у нас есть ай ди клиента, то тут понятно, если нет ай ди, то пишем рекомендацию, чтобы данные приходили с ай ди,  \n",
    ">чтобы можно было понять это один человек или нет "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если у нас id пользователя встречается не одни раз в таблице и есть другие поля которые должны быть всегда одни и те же,  \n",
    ">напримем пол и прочее, то нужно проверить у всех ли пользователей все значения одинаковые в этом столбце.  \n",
    ">Это может быть не только ай ди, любое уникальное поле, которое повторяется и для каждого этого поля есть другое  \n",
    ">поле, которое не должно меняться, нужно проверять а действительно ли это поле не меняется.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Изучение пропусков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Не забываем про ИИ.  \n",
    ">Пишем название столбца (именно что они значат, то есть образование, пол и прочее), говорим, что есть пропуски.  \n",
    ">И просим предложить причины этих пропусков. Если видим важное, то используем для рекомендаций, выводов и замены пропусков в предобработке.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Проверяем на пропуски"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Когда смотрим на пропуски, то нужно ответить на вопрос так и должно быть, это нормально, что пропуски в этих колонках.   \n",
    ">Когда смотрим на пропуски по категориям, то думаем есть ли закономерность, не случайно ли распределение по категориям  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Когда мы встречаем пропуски, прежде всего, нужно ответить на вопрос, существует ли закономерность в появлении пропусков.   \n",
    ">Иными словами, не случайно ли их возникновение в наборе данных.  \n",
    ">Случайно, значит нет закономерности с соседними столбцами, то есть пропуски есть для разных значений.  \n",
    ">А могут быть неслучайные, то есть существует явная закономерностЬ, что пропуски есть только у сторок с общими занчениями в другом столбце.    \n",
    ">Чтобы это проверить, нужно взять столбец с пропусками, отфильтровать только пропуски (взять их) и  \n",
    ">посмотреть как эти пропуски распределены по другой переменной.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Первое что нужно сделать, когда мы видим пропуск или выброс, это проверить является ли оно случайным.  \n",
    ">То есть посмотреть не относятся ли все выбросы к одной категории. Если это так, то это уже не случайно и мы нашли аномалию, которую можно изучать.  \n",
    ">Если у нас случайны разброс пропусков в категориях, то значит тут есть случайность.  \n",
    ">Например, у нас возраст 0, и мы видим, что больше всего это у женщин. Следовательно получаем гипотезу, что женщины не хотят сообщать свой возраст.  \n",
    "- В пропусках мы можем определить какие категории, платформы и прочее не собираются данные. Смотрим пропуски, далее смотрим у каких категорий их больше,  \n",
    ">и получаем вывод, что нужно обратить внимание на эти категории или системы, почему там пропуски"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">`find_columns_with_missing_values`  \n",
    ">`check_na_in_both_columns`  \n",
    ">`analys_by_category_gen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_missed = my_module.find_columns_with_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Посмотрим на строки датафрейма с пропусками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1_missed = series_missed['col1']\n",
    "col2_missed = series_missed['col2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1_missed.head()\n",
    "col2_missed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Посмотрим сколько пропусков в обоих колонках вместе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.check_na_in_both_columns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Изучаем пропуски по категориям"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Смотрим на все поля  \n",
    ">in_category_pct говорит о том сколько в этом значении категории изучаемых значений  \n",
    ">in_column_pct говорит о том сколько процентов изучаемого значения данного значения категории в общем  \n",
    ">total_count_pct помогает анализировать in_column_pct, так как мы видим сколько занимает это значение в общем  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = my_module.analys_by_category_gen(df, series_missed)\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Изучение выбросов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Не забываем про ИИ.  \n",
    ">Пишем название столбца (именно что они значат, то есть образование, пол и прочее), говорим, что есть выбросы.  \n",
    ">Обязательно приводим значения выбросов, самые характерные, чтобы дать ИИ болше информации.\n",
    ">И просим предложить причины этих выбросов. Если видим важное, то используем для рекомендаций, выводов и замены выбросов в предобработке.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Когда смотрим на выбросы, то нужно ответить на вопрос так и должно быть, это нормально, что выбросы в этих колонках.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Выбросы это не только просто сильно большое или сильно маленькое значение.  \n",
    "- Выбросы нужно также смотреть по мультипараметрам, с помощью моделей и искать аномалии.  \n",
    "- Выброс это то, что отделяется от других, что выбивается из общей картины. Следовательно это что-то особенное.  \n",
    "- Тажке выбросы говорят не только о плюсах, но и о минусах. Выбросы могут сказать, что у нас что-то сломалось.  \n",
    ">Что-то не записывается, или работает с багами. Все это можно увдитеь по выбрасам и аномалиям.  \n",
    "- Обязательно посмотреть выбросы в разрезе категорий, так как мы сможем сделать выводы об их источнике.  \n",
    "- Если мы работаем со строгой отчетностью, то тут любой выброс это уже инсайт и нужно идти разбираться откуда это взялось.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если мы во время изучения данных выявили потенциальные выбросы, то нужно их отдельно изучить.    \n",
    ">Для этого создаем датафрейм с нужными значениями и помещаем его в `Series`,  \n",
    ">индекс это название колонки, в которой мы изучаем выброс.  \n",
    ">Далее отдаем этот  `Series` в функцию `analys_by_category_gen`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Сначала изучим потенциальные выбросы, которые мы выявили при изучении колонок.  \n",
    ">У нас в количестве детей есть значение 20.   \n",
    ">Изучим его подробнее.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Важно при изучении колонок записывать выбросы отдельно и потом коппировать сюда.  \n",
    ">А тут нужно изучить эти значения отдельно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_series = pd.Series([df[df.children == 20]], index=['children'])\n",
    "gen = my_module.analys_by_category_gen(df, outliers_series)\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Смотрим на выбросы используя Z-score  \n",
    ">`detect_outliers_Zscore`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_outliers = my_module.detect_outliers_Zscore()\n",
    "# сначала смотрим на значения с большим количеством выбросов\n",
    "series_outliers['col'].col.value_counts().to_frame('outliers')\n",
    "# затем уже изучаем определенные датафреймы в series_outliers\n",
    "series_outliers['col'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Смотрим на выбросы используя квантили  \n",
    ">`detect_outliers_quantile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_outliers = my_module.detect_outliers_quantile(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Посмотрим на строки датафрейма с пропусками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1_outliers = series_outliers['col1']\n",
    "col2_outliers = series_outliers['col2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1_outliers.head()\n",
    "col2_outliers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Изучить выбросы по категориями  \n",
    ">`analys_by_category_gen`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Смотрим на все поля  \n",
    ">`in_category_pct` говорит о том сколько в этом значении категории изучаемых значений  \n",
    ">`in_column_pct` говорит о том сколько процентов изучаемого значения данного значения категории в общем  \n",
    ">`total_count_pct` помогает анализировать `in_column_pct`, так как мы видим сколько занимает это значение в общем  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = my_module.analys_by_category_gen(df, series_outliers)\n",
    "next(gen) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Изучение отрицательных значений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Не забываем про ИИ.  \n",
    ">Пишем название столбца (именно что они значат, то есть образование, пол и прочее), говорим, что есть отрицательные значения там где их быть не должно.  \n",
    ">Обязательно приводим значения, самые характерные, чтобы дать ИИ болше информации.\n",
    ">И просим предложить причины этих отрицательных значений. Если видим важное, то используем для рекомендаций, выводов и замены отрицательных значений в предобработке.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Очень важно, если у нас есть столбец, в котором не должно быть отрицательных значений, то нам нужно отдельно изучить положительные и отрицательные значения.  \n",
    ">И те и те посмотреть по категориям.  \n",
    ">И на основе этого изучения мы моежм заметить причины отрицательных значений.  \n",
    ">Например, в колонке стажа у нас очень много отрицательных значений и есть положительные значения.  \n",
    ">Мы отдельно посмотрели отрицательные значения и они в основном принадлежат работающим людям.  \n",
    ">А положительные пренадлежат пенсионерам.   \n",
    ">Важно и полоительные и отрицательные значения посмотреть их макс и мин.   \n",
    ">Вот мы для стажа посмотрели макси и мин и видим, что отрицательные значения похожи на реальные значения в годах.   \n",
    ">А вот положительные слишком большие, и далее мы поняли, что это данные в часах.  \n",
    ">В итоге у нас уже много предположений, которые помогут выяснить откуда появляются странные данные в этом столбце.  \n",
    ">К тому же мы можем попробовать заменить отрицательные значения, если у нас есть уверенность на основе анализа.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Изучаем отрицательные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_negative = my_module.find_columns_with_negative_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Определяем в каких колонках не должно быть орицательных значений.  \n",
    ">Колонки в которых допустимы отрицательные значения удаляем из `series_negative`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Изучим отрицательные значения в разрезе категорий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Смотрим на все поля  \n",
    ">in_category_pct говорит о том сколько в этом значении категории изучаемых значений  \n",
    ">in_column_pct говорит о том сколько процентов изучаемого значения данного значения категории в общем  \n",
    ">total_count_pct помогает анализировать in_column_pct, так как мы видим сколько занимает это значение в общем  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = my_module.analys_by_category_gen(df, series_negative)\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Изучение нулевых значений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Не забываем про ИИ.  \n",
    ">Пишем название столбца (именно что они значат, то есть образование, пол и прочее), говорим, что есть нули там, гед их быть не должно.  \n",
    ">И просим предложить причины этих нулей. Если видим важное, то используем для рекомендаций, выводов и замены нулей в предобработке.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Изучаем нулевые значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_zeros = my_module.find_columns_with_zeros_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Определяем в каких колонках не должно быть нулевых значений.  \n",
    ">Колонки в которых допустимы нулевые значения удаляем из `series_negative`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dob_years           children  days_employed  dob_years educ...\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "series_zeros = series_zeros.drop('children')\n",
    "series_zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Изучим нулевые значения в разрезе категорий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Смотрим на все поля  \n",
    ">in_category_pct говорит о том сколько в этом значении категории изучаемых значений  \n",
    ">in_column_pct говорит о том сколько процентов изучаемого значения данного значения категории в общем  \n",
    ">total_count_pct помогает анализировать in_column_pct, так как мы видим сколько занимает это значение в общем  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = my_module.analys_by_category_gen(df, series_zeros)\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">После изучения данных у нас могут возникнуть вопросы по определенным значениям, это возможно не выбросы,  \n",
    ">мы просто хотим подробнее их изучить.    \n",
    ">Для этого создаем датафрейм с нужными значениями и помещаем его в `Series`,  \n",
    ">индекс это название колонки, в которой мы изучаем выброс.  \n",
    ">Далее отдаем этот  `Series` в функцию `analys_by_category_gen`.  \n",
    ">Нужно сделать специальную функцию для этого, чтобы не использовать `analys_by_category_gen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_series = pd.Series([df[df.col_for_check == value_for_check]], index=['col_for_check'])\n",
    "gen = my_module.analys_by_category_gen(df, check_series)\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Также мы можем изучить любые столбцы (или часть столбцов) по категориям.  \n",
    ">То есть мы изучаем как распределены элементы по категориям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_series = pd.Series([df[df.col_for_check == value_for_check]], index=['col_for_check'])\n",
    "gen = my_module.analys_by_category_gen(df, check_series)\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Сделать функцию определения выбросов на основе машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Дополнительные моменты, которые стоит проверить и изучить \n",
    "- Проверить на сложные выбросы, типа у нас есть статус и возраст и мы видим что студент имеет возраст 60 лет, это реально, но уже подозрительно.  \n",
    ">Вот таких моментов может быть много, но нужно додуматься, чтобы найти такие комбинации, но это важно делать. \n",
    "- важно проверить на корректность данные, то есть смотрим по отдельности каждый столбец и изучаем мин, макс, и другие параметры, и  \n",
    ">думаем, это физически реально. И особенно, когда у нас несколько связаных параметров, нет ли между ними противоречия.  \n",
    ">Например, у нас есть дата показа рекламы и есть дата создания рекламы, естественно создание должно быть раньше, это нужно проверить.  \n",
    "- Проверяем данные ошибки  \n",
    ">Ошибки которые не являются дублями, пропусками или выбросами.  \n",
    ">Это сложно сделать, хотя бы заметить явные ошибки\n",
    "- Проверить на ошибки согласованности  \n",
    ">Например, у нас пользователь с одним ай ди имеет разные имена. \n",
    ">`display(df.groupby('name')['age'].nunique())`\n",
    "- вообще нужно придумать разные проверки для колонок, особенно связанных. И провести эту проверку. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Из наблюдений собираем важные выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-collect",
   "metadata": {},
   "source": [
    ">Принимаем решение, как именно мы будем проводить обработку, почему именно так, *зафиксировать рекомендации.  \n",
    ">То есть отвечаем на вопрос, что будем делать с выбросами, что будем делать с null.  \n",
    ">Будет идеально если тут зафиксировать рекомендации  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Промежуточный вывод**\n",
    ">\n",
    "- **children** Присутствует 47 отрицательных значений с \"-1\", а также аномалия в виде 20 детей ...\n",
    "- **days_employed** Большая часть данных стобца со знаком \"-\". Однако, эти данные представляют из себя 84% всей выборки. ... будут заменены на .. исходя из определенного критерия, который будет описан далее. \n",
    ">    - Причины пропущенных значений в столбцах **days_employed** и **income**:\n",
    ">        - Во-первых, это может быть из-за неправильной выгрузки данных. Оставим это предположение до того момента, пока не убедимся в неверности других предположений.**Наиболее вероятно**\n",
    ">        - Во-вторых, одной из гипотез было предположение об отсутствии трудового опыта у данной части выборки. Однако, если распределение по возрасту в данной группе равномерное по всем возрастам выборки. Также большая доля этой части выборки трудоустроена. **Гипотеза не подтверждена**\n",
    ">        - В-третьих, возможно, что эта часть выборки не имеет официального трудоустройства. Данная гипотеза вызывает сомнение в связи с тем, что при наличии достаточно большого стажа работы у представителей выборки у ее представителей нет официального трудового стажа. К тому же 18.9% данной выборки являются госслужащими. **Гипотез не подтверждена**\n",
    "- **age** .. 0 возраст у 101 человека.\n",
    "- **education & education_id** Необходимо будет привести данную категорийнуй переменную к общему виду. Избавиться от разного регистра. Но можно не тратить на это время и использовать следующий столбец **education_id**. Это позволит использовать меньше памяти и не повлияет на качество анализа.\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Важно, когда удаляем строки, то делаем сброс индекса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Не забываем про ИИ  \n",
    ">Когда мы проводим предобработку данных, то первый вопрос мы себе задать следующий\n",
    ">Какава вероятнсоть, что это является истиной? Если вероятнсоть ниже 60 прцоентов, то это делать не стоти и может лучше оставить как есть или не трогать этот столбец.  \n",
    ">Например, у нас дубли или отрицательные значеия и мы выдвинули гипотезу, что это просто неправильный знак и хотим взять модель числа.  \n",
    ">Но если мы подумаем, а высокая ли вероятность, что число просто с неверным знаком, то вероятнсот этого низкая.  \n",
    ">Поэтому это делать не нужно.   \n",
    ">Другое дело у нас датафрейме 1 прцоент полных дублей и при этом у нас есть достаточно точные колонки типа зарплаты с точностью до рублей или стаж в днях.  \n",
    ">Вот тут мы можем с высокой вероятностью утверждать, что это дубли, так как мало вероятно что будет две записи настолько точно совпадать.  \n",
    ">Поэтому сначала думаем насколько вероятна та гипотеза, которую мы выдвинули и хотим по ней изменить наши данные.  \n",
    ">Тут лучше придерживаться правила не навреди. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Когда удаляем значения из категориальных столбцов pandas, и в этом столбце нет больше таких занчений, которые удалил.  \n",
    ">То нужно удалить это значение из категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.gender == 'XNA'].index, inplace=True)\n",
    "df['gender'] = df['gender'].cat.remove_unused_categories()\n",
    "df.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обрезание неполных временных периодов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если у нас датасет за год, например, и первый или последний месяц неполные, то их лучше выбрасить, если мы будем  \n",
    ">расчитывать месячные метрики.  \n",
    ">Но сначала конечно нужно проанализировать столбцы без обрезания, чтобы убедиться, что там нет ничего необычного.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор нужных столбцов для дальнейшей работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Сохраним исходный датафрейм в переменную df_origin, чтобы была возможность вернуться к нему\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origin = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Удаляем ненужные столбцы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['col1', 'col2'], axis=1)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Думаем, какие колонки нам нужны, выбираем только их для дальнейшей работы.  \n",
    ">Остальные убираем в другой датасет. \n",
    "- Важно после изученя данных сначала убрать не нужные столбцы, а потом уже заниматься преобразованием (удалением пропусков и выбросов).  \n",
    ">Думаем прежде чем удалять строки, так как возможно лучше удалить столбец и строки удалять будет не нужно.  \n",
    "- Пишем почему выбираем определенные столбцы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка выбросов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Не забываем про нулевые значения и отрицательный.  \n",
    ">В столбцах, где их быть не должно, они являются выбросами.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">С обработкай нулевых и отрицательных значений нужно быть внимательным.  \n",
    ">Нужно сначала хорошо подумать, откуда могло это появиться,  \n",
    ">тут поможет анализ этих значений в предыдущей главе.  \n",
    ">Думаем откуад появилось отрицательное или нулевое занчение,  \n",
    ">и если у нас есть гипотезы, которые похожи на правду (мы думаем что вероятность их истины больше 60%),  \n",
    ">то мы обрабатываем их исходя из гипотезы.  \n",
    ">Например, -1 часто бывает как отсутсвие чего-то, то есть мы в зависимости от контекста можем заменить его на 0.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Важно каждый раз, когда мы удаляем что-то из датафрейма, то убедиться, что мы удалили столько строк, сколько и хотели.  \n",
    ">Для этого выводим размер датафрейма до удаления.  \n",
    ">Смотрим сколько строк мы хотим удалить.  \n",
    ">Далее не сохраняя в датафрейм удаляем строки и смотрим верный ли итоговый размер.  \n",
    ">Если все верно, то удаляем уже с сохранением.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Не забываем, что выбросы мы также можем заменять на медианные значения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21525"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21478"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df[df.children >= 0]\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Посмотрим где у нас отрицательные значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.check_negative_value_in_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Посмотрим где у нас нулевые значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.check_zeros_value_in_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Обрабатываем нулевые и отрицательные значения, затем снова проверяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [negative]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_module.check_negative_value_in_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zeros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [zeros]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_module.check_zeros_value_in_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Также нужно обработать выбросы, которые мы обнаружили при изучении данных.  \n",
    ">Это могут быть любые колонки со значениями, которые не моут быть в реальности.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Нужно сначала обработать выбросы, а потом уже обрабатываться пропуски.  \n",
    ">Так как мы заоплняем пропуски, учитывая значения в колонке, которые возможно мы потом удалим.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Помним про нулевые и отрицательные значения\n",
    "- Нулевые значения, отрицательные значения являются выбросами, если они не могут быть у этой колонки.  \n",
    "- Очень важно понимать, когда выброс можно отбросить и он реально выброс и когда нельзя.  \n",
    ">Опираемся на физику параметра, думаем это значение физически возможно.  \n",
    "- Также выброс может казаться выбрасом, но для бизнеса это не выброс.  \n",
    ">Например у нас суммы покупок и одна покупка сильно выделяется, а там просто человек купил супе дорогой каньяк, например.  \n",
    "- Когда хотим обрезать выбросы, то думаем, какой порог может быть физически реальным и по нему режем, а не просто так берем какой-то перцентиль.  \n",
    ">Всегда нужно думать с точки зрения физического возможного значения параметра и по нему резать (подумать а какое значение может быть максимально реальным и по нему обрезать)\n",
    "- Если мы имеем дело со строгой отчестностью, то выбросы убирать нельзя, нужно разобраться откуда они.  \n",
    "- Если мы не можем с увереностью сказать, что это выброс, то нам не стоит его выкидывать, но работать как то нужно с ними,  \n",
    ">тогда, логарифмируем (лучше использовать натуральный логарифм) эту колонку и работаем с такими значениями (тогда выбросы сожмуться).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">После удаления выбрасов, можно снова выполнить пункт про изучение выбрасов, так как выбросы могут появиться новые,   \n",
    ">если у нас например выбросы были слишком нереальные значения, когда мы от них избавимся, будет лучше видно другое"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка пропусков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Прежде чем обрабатывать пропуски, нужно подумать а можем ли мы их заменить исходя из имеющихся столбцов.  \n",
    ">Например, у нас есть столбец с пропусками возраст, и есть стаж,  \n",
    ">мы можем возраст заменить так стаж + 18 + 5  \n",
    ">Аналогично другие ситуации нужно сообразить как можно заменить пропуски.  \n",
    ">И только если нет идей, тогда уже заменяем на медиану, например, по группам.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.check_missed_value_in_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если решии заменять прпоуски значениями, учитывая категории, то нужно убедиться, что размер этих категорий достаточный."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Посмотрим размеры групп, если заменять внутри этих групп"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_columns = ['education', 'family_status', 'gender', 'income_type']\n",
    "value_column = 'total_income'\n",
    "my_module.check_group_count(df, category_columns, value_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Заполним пропуски в группах от 10 элементов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[value_column] = my_module.fill_na_with_function_by_categories(df, category_columns, value_column, func='median', minimal_group_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Проверим сколько у нас осталось пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.check_missed_value_in_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если пропуски остались, то убираем какую-нибудь категорию и повторяем."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dried-general",
   "metadata": {},
   "source": [
    ">что-то изменили - > посмотрели не изменилось ли количество дублей   \n",
    ">`check_duplicated`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.check_duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Увидели пропуск — подумайте, нормально ли это. Сколько вообще пропусков может быть в этом столбце?   \n",
    ">К примеру, в списке с электронными адресами пользователей, согласных на рассылку, будет много пропусков. Далеко не все предоставляют email."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Можно использвоать такой подход\n",
    "- если количество пропусков меньше 5 процентов, то удаляем (лучше меньше 1 процента)\n",
    "- если количество пропусков от 5 до 20 процентов, то подбираем чем заменить, удалять не стоит\n",
    "- если больше 20 процентов, то не трогаем, так как исказим"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Но оставляя пропуски, нам нужно помнить, что мы не можем по этим полям считать корреляцию с другими,   \n",
    ">так как пропуски испортят расчет коэффициента корреляции. Аналогично другие метрики могут считаться некорректно.  \n",
    ">Поэтому, если мы будем считать показатели по столбцу с пропусками, то их нужно либо убирать, либо этот столбец не использовать для расчетов.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Для категориальных переменных оставлять пропуски нельзя, так как мы скорее всего будем группировать по ним и смотреть разные разрезы.  \n",
    ">Поэтому в худшем случае, если не можем ничем заменить, и нет уверености, что пропуск можно заполнить пустой строкой (если значения физически нет),  \n",
    ">то создаем категорию например `other` из пропусков.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если у нас пропуски в категориальной переменной и есть разные периоды или просто данные разбиты на части (то есть эта категориальная переменная повторяется),  \n",
    ">то мы можем взять ещё какую-нибудь переменную, у которой нет пропусков, где пропуски у первой переменной и далее посмотреть другие периоды  \n",
    ">Таким образом у нас будет предыдущий период, где будет занчение второй переменной и первой и если в нескольких периодах они одинаковые, то мы можем  \n",
    ">заполнить и пропуски этим значением.   \n",
    ">Ещё раз схема такая - берем 2 поля одно с пропусками, другое без, получаем новую таблицу, в этой таблице оставляем только униклаьные значения в поле без пропусков,  \n",
    ">по этому полю будем джойнить. Далее в основнйо таблице дропаем описание и создаем новое описание из таблицы справочника.    \n",
    ">`fill_missing_values_using_helper_column`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.fill_missing_values_using_helper_column()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Заполняем пропуски учитвая категории  \n",
    ">`fill_na_with_function_by_categories`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Важно следить, чтобы категории, по которым будем заполнять пропуски были обработаны.  \n",
    ">Если у нас в категориальной переменной есть значение с большой буквы и с маленькой, то это одна категория,  \n",
    ">но замена будет идити по двум, чтобы такого не было, нужно сначала обработать  категориальную переменную.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Также важно, чтобы в группах по которым мы будем считать значение для заополения было достаточно значений  \n",
    ">для выбранной функции.  \n",
    ">Например, если мы решили брать среднее, а в группе у нас 5 значений, то среди них может быть выброс и наше среднее будет некорректно.  \n",
    ">Лучше в такой ситуации брать группу побольше для этих микрогрупп.  \n",
    ">В идеале группы должны быть от 30 элементов.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Можно посмотреть какой процент группах без значений "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df.groupby(['education', 'family_status', 'gender', 'income_type'])['total_income'].sum()\n",
    "(temp == 0).sum() * 100 / temp.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.fill_na_with_function_by_categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Сделать функцию заполнения пропусков с помощью машинного обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">После удаления пропусков и выбросов желательно проверить какой прцоент строк мы удалили.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка дубликатов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Все значения в колонках во всех таблицах нужно привести к нижнему регистру и по возможности к одному языку,  \n",
    ">для перевода к одному языку можно использовать словарь, с помощью которого изменить неправильный язык  \n",
    ">Это нужно, чтобы когда будем соединять таблицы, у нас условие соеденения правильно сравнивало равные значения.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Можно посмотреть снвоа на дубликаты после обработки пропусков.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">`check_duplicated`   \n",
    ">`find_columns_with_duplicates`   \n",
    ">`check_duplicated_combinations_gen`    \n",
    ">`get_duplicates_value_proportion_by_category`  \n",
    ">В первую функцию можно передавать весь датафрейм и можно выбирать нужные столбцы для проверки на дубли и передавать их.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.check_duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.check_duplicated_value_in_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.find_columns_with_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Заполним пропуски в группах от 10 элементов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[value_column] = my_module.fill_na_with_function_by_categories(df, category_columns, value_column, func='median', minimal_group_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>total_income</th>\n",
       "      <td>63 (0.3%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 missed\n",
       "total_income  63 (0.3%)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_module.check_missed_value_in_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если есть дубли, и мы считаем, что это не дубли, а просто разделились данные,    \n",
    ">то объединеняем записи, которые имеют одинаковые значения ключевых признаков.  \n",
    ">`merge_duplicates`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.merge_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если мы не уверены, что дубль является дублем и не хотим удалять, то можно  использовать  \n",
    ">маркировку дублей,  можно добавить новую колонку, которая будет содержать информацию о том,   \n",
    ">является ли строка дубликатом или нет.  \n",
    ">`df['is_duplicate'] = df.duplicated()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_duplicate'] = df.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Подумать, а можем ли мы обогатить данные, что разделит дубли.  \n",
    ">То есть возможно в наших данных нет какого-то столбца, и тогда дубли уже не будут дублями. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если уверены, что это дубли, то удаляем их  \n",
    ">`df.drop_duplicates()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Приведение данных к удобной форме"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если у нас в столбце, например, стаж данные в днях, то это нужно преобразовать в года.  \n",
    ">Также если у нас в других столбцах данные в формате, который нужно изменить для лучшего анализа, то делаем это.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Округлим значения в поле дохода до целого.  \n",
    ">Целая часть выглядит реальной. А с дробной частью нужно разбираться почему стоько знаков.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>children</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>family_status</th>\n",
       "      <th>gender</th>\n",
       "      <th>income_type</th>\n",
       "      <th>debt</th>\n",
       "      <th>total_income</th>\n",
       "      <th>purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>высшее</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>0</td>\n",
       "      <td>253876</td>\n",
       "      <td>покупка жилья</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   children  age education    family_status gender income_type debt  \\\n",
       "0         1   42    высшее  женат / замужем      F   сотрудник    0   \n",
       "\n",
       "   total_income        purpose  \n",
       "0        253876  покупка жилья  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.total_income = df.total_income.round().astype('int32')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Посмотрим сколько у нас людей с полом XNA осталось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(df.gender == 'XNA').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Посмотрим кто это"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>children</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>family_status</th>\n",
       "      <th>gender</th>\n",
       "      <th>income_type</th>\n",
       "      <th>debt</th>\n",
       "      <th>total_income</th>\n",
       "      <th>purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10701</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>неоконченное высшее</td>\n",
       "      <td>гражданский брак</td>\n",
       "      <td>XNA</td>\n",
       "      <td>компаньон</td>\n",
       "      <td>0</td>\n",
       "      <td>203905</td>\n",
       "      <td>покупка недвижимости</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       children  age            education     family_status gender  \\\n",
       "10701         0   24  неоконченное высшее  гражданский брак    XNA   \n",
       "\n",
       "      income_type debt  total_income               purpose  \n",
       "10701   компаньон    0        203905  покупка недвижимости  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[df.gender == 'XNA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Всего 1 человек. И мы не можем идентифицировать его пол.  \n",
    ">Удалим, чтобы не мешало анализировать графики.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21402"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21401"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.drop(df[df.gender == 'XNA'].index, inplace=True)\n",
    "df['gender'] = df['gender'].cat.remove_unused_categories()\n",
    "df.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Категоризация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если у нас есть категориальная переменная, в которйо больше 3 значений, то нужно подумать а не можем ли мы из нее сделать  \n",
    ">новую категориальную переменную с 2-3 значениями, но тут важно, чтобы это несло смысл. Тут нам может помочь ИИ. И сообразительнсоть. Часто сразу не заментны возможные категории,  котоыре несут смысл.  \n",
    ">Тут исходим из смысла, наша задача созадть перменную, которая добавит нашему исследованию новый смысл, даст как бы новый разрез, и это улучшит   \n",
    ">качество наших выводов.    \n",
    ">Например, у нас столбец семейный стату, и там 6-7 статусов, мы можем собрать их в 2 семейный статус и не семейный статус.  \n",
    ">Тут отлично помогает ИИ. Пишешь ему название переменной, униальные значения в ней,  \n",
    ">и просишь придумать возможную новую категориальнуюд переменную из 2-3 значений.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Вообще при категоризации ИИ очень хорошо помогает, он может дать идеи возможных категорий на оснвое имеющихся значений.  \n",
    ">Поэтому можно все столбцы прогонять через ИИ и смотреть что он предлагает, если есть то , что даст новый разрез нашим данным, то созадем категорийю.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Важно, когда мы создаем категории, то всегда смотреть value_counts.  \n",
    ">И делаем так, чтобы в каждой группе было достаточно элементов, хотя бы больше 30, а лучше больше 100.  \n",
    ">Иначе выводы будут некоректные.  \n",
    ">В идеале, чтобы количество элементов в каждой группе было от 1000.  Лучше изменить диапазон и забрать часть данных от другой категории.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Важно, когда создаем категориальную переменную, то даем ей тип `category`  \n",
    ">Чтобы она появилась на графиках (так как идет фильтрация на числовые и категориальные)  \n",
    ">и чтобы места меньше занимала"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Придумываем какие колонки можно дополнительно сделать из имеющихся.  \n",
    ">Например у нас есть колонка длительность звонков, и 0 это пропущенный звонок,  \n",
    ">мы можем сделать колонку is_missed, в которой будет true или false  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Стараемся сделать категориальную колонку с да нет для всех возможных колонок.  \n",
    ">Например, у нас колонка количество детей и есть 0, 1, 2, 3, 4, 5 мы созадем колнку  \n",
    ">есть дети или нет. 2 значения  \n",
    ">Это очень полезно, так как мы можем посмотреть это на графиках и проверить гипотезы  \n",
    ">стат тестами.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Смотрим на колонки и думаем можно ли из нее сделать колонку с 2 значениями,  \n",
    ">например есть и нет что-то "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Очень важно, когда мы создаем новые колонки, в которых используем несколько дургих, то нужно проверить распределение этой новой переменной, особенно выбросы.  \n",
    ">Например, у нас начальная и конечная дата сессии и мы считаем длительность сессии. Вот тут нужно посмотреть какая минимальная длительность  \n",
    ">и какая максимальная. Ну и естественно проверить есть ли длительность 0 и меньше нуля.  \n",
    ">Таким образом мы можем найти инсайты уже после создания новых колонок, хотя в изначальных данных этих инсайдов не было видно.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Обычная категоризация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Категоризация помогает избежать проблемы с разреженными данными, когда у нас есть слишком много групп с небольшим количеством элементов.   \n",
    ">Это может привести к некорректным выводам и ошибкам в анализе.\n",
    ">Категоризация нужна, чтобы образовать группы, в которых достаточно значений для использования статистических методов.  \n",
    ">И вообще, если в группе 1-10 элементов, например у нас возраст пользователей и 5 человек с возрастом 22, 3 человека с возрастом 23 и так далее.  \n",
    ">Мы не можем разбивать по таким группам, так как их размер небльшой и выводы будут некорректные, поэтому нам нужно собрать их в группы,  \n",
    ">чтобы у нас были группы с достаточным размером.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Если у нас категориальная переменная имеет много значений, то мы не можем номрально с ней работать.  \n",
    ">Так как мы не можем построить графики по ним, так как их много и они не числовые. Не можем сравнить их все.  \n",
    ">Поэтому нам нужно сократить категории.  \n",
    "- Нужно посмотреть на данные и подумать можем ли мы разделить их по сегментам рынка или по другим категориям, которые нам помогут.  \n",
    "- Мы можем категоризировать на основе и числовых и категориальных столбцов. То есть мы можем из категориальной переменной сделать  \n",
    ">другую категориальную, уменьшив или увеличив разбиение.   \n",
    "- добавление категорий обогощает данные, при чем категории могут формироваться не из одной колонки, а из серии, то есть чтобы попасть  \n",
    ">в определенную категорию значения столбцов должно быть такое то, а не только один столбец определяет категорию.  \n",
    "- категории могут быть да нет, то есть состоять из двух значений, например, у нас есть данные о рекламе и столбец где она показвалась,  \n",
    ">и у нас много много разных устройств. Мы можем разбить на да нет, то есть показвалась реклама по телеку или нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Мы можем разбить данные на категории двумя способами\n",
    "- разбивать на равные части  \n",
    ">подходит, когда \n",
    ">    - диапазон значений является равномерным и имеет линейную структуру  \n",
    ">    - мы понимаем на какие интервалы хотим разбить данные    \n",
    ">    - мы хотим разделить диапазон значений на равные части для удобства анализа.\n",
    "- разбить на основе квантилей  \n",
    ">подходит, если   \n",
    ">    - диапазон значений имеет неравномерную структуру\n",
    ">    - мы не можем понять какие интервалы выбрать\n",
    ">    - хотим выделить группы с конкретными характеристиками (например, группы с низким доходом, средним доходом и высоким доходом)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Выбираем нужные способ и используем  \n",
    ">`create_category_column`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Чтобы посмотреть распределение по квантилям используем `my_module.quantiles_columns()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.quantiles_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.create_category_column()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Сделаем следующие группы\n",
    "- до 30 лет\n",
    "- от 30 до 40 лет\n",
    "- от 40 до 50 лет\n",
    "- от 50 до 60 лет\n",
    "- старше 60 лет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['до 30', '30-40', '40-50', '50-60', 'старше 60']\n",
    "bins = [-np.inf, 30, 40, 50, 60, np.inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30-40        5704\n",
       "40-50        5241\n",
       "50-60        4520\n",
       "до 30        3804\n",
       "старше 60    2132\n",
       "Name: age_cat, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['age_cat'] = my_module.create_category_column(df.age, labels=labels, bins=bins)\n",
    "df['age_cat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Категоризация с использованием лемматизации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если у нас есть столбец и мы хотим его лематизировать, то используем функцию  \n",
    ">`lemmatize_column`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Чтобы создать лемы для словаря категоризации, можно посмотреть имеющиеся предложения и использовать \n",
    ">```\n",
    ">m = Mystem()\n",
    ">m.lemmatize('образованием')\n",
    ">```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "m.lemmatize('образованием')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.lemmatize_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorization_dict = {\n",
    "    'недвижимость': ['жилье', 'недвижимость']\n",
    "    , 'образование': ['образование']\n",
    "    , 'автомобиль': ['автомобиль', 'машина']\n",
    "    , 'свадьба': ['свадьба'] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "недвижимость    10779\n",
       "автомобиль       4288\n",
       "образование      3997\n",
       "свадьба          2337\n",
       "Name: purpose_new, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['purpose_new'] = my_module.categorize_column_by_lemmatize(df.purpose, categorization_dict, use_cache=True)\n",
    "df['purpose_new'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если нужно, уддалим старую колонку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>children</th>\n",
       "      <th>dob_years</th>\n",
       "      <th>education</th>\n",
       "      <th>family_status</th>\n",
       "      <th>gender</th>\n",
       "      <th>income_type</th>\n",
       "      <th>debt</th>\n",
       "      <th>total_income</th>\n",
       "      <th>purpose</th>\n",
       "      <th>dob_cat</th>\n",
       "      <th>total_income_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>высшее</td>\n",
       "      <td>женат / замужем</td>\n",
       "      <td>F</td>\n",
       "      <td>сотрудник</td>\n",
       "      <td>0</td>\n",
       "      <td>253876</td>\n",
       "      <td>Недвижимость</td>\n",
       "      <td>40-50</td>\n",
       "      <td>200-500 тыс</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   children  dob_years education    family_status gender income_type debt  \\\n",
       "0         1         42    высшее  женат / замужем      F   сотрудник    0   \n",
       "\n",
       "   total_income       purpose dob_cat total_income_cat  \n",
       "0        253876  Недвижимость   40-50      200-500 тыс  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.drop('purpose', axis=1).rename(columns={'purpose_new': 'purpose'})\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">С помощью лематизации мы можем сократить количество категорий.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Например мы можем выделить группы:\n",
    "- операции с автомобилем (ключевое слово - автомобиль)\n",
    "- операции с недвижимостью (ключевые слова: жилье, недвижимость)\n",
    "- проведение свадьбы (ключевое слово: свадьба)\n",
    "- получение образования (ключевое слово: образование)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Используем функцию  \n",
    ">`categorize_column_by_lemmatize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.categorize_column_by_lemmatize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если мы хотим преобразовать категории в числа, то мы можем использовать \n",
    "- lable encoding  \n",
    ">Заменяем быквы числами. Хорошо работает, когда у нас порядковые категориальные переменные.  \n",
    ">Не забываем про порядок, если у нас алфавитный порядок наших категорий соотвествует числовому, то ок,  \n",
    ">если нет, то нам нужно самим определить порядок чисел, чтобы они соответствовали категориям в нужном порядке.  \n",
    "- one hot encoding  \n",
    ">Если у нас категориальная переменная не упорядочиваемая, то лучше использовать one hot encoding, чтобы разница между числами не вносила шум,  \n",
    ">так как черный и белый и красный цвет закодированные 1, 2, 3 вносят смысл количества, но они не имеют этого свойства.  \n",
    "-  target encoding  \n",
    ">замена категориальной переменной на каую-то статистику по одной из категорий внутри этой переменной.  \n",
    ">Например у нас категориальная переменная это наличие задержки. Значение задержан / незадержан. Мы кодируем их как 0 и 1. Далее мы берем и считаем по каждой группе (для задержан и для незадержан)  \n",
    ">статистику, например, среднее и получаем столбец, где вместо каждой буквы будет ее среднее.  \n",
    ">Тут важно делать регуляризацию. Так как маленькие группы могут иметь сильно  зашумленные статистики, так как если у нас  \n",
    ">группа из 5 значений, то среди них может быть легко экстремальное одно и оно сбивает статистику, поэтому добавляем штраф всем статистикам.  \n",
    ">Регуляризация это что-то похожее на сглаживание.  \n",
    ">Как это делается \n",
    ">    - берем считаем среднее по таргету (целевой переменной, то есть той, по которой мы счтаем статистику) всей таблице (то есть не делим на категории)  \n",
    ">    - Далее используем следующую формулу для сглаженного значения среднего по конкретной группе:   \n",
    ">      (среднее по группе * количество элементов в группе + среднее по таргету без учета категорий * размер регуляризирующей группы) / (количество элементов в категории + размер регуляризирующей группы)  \n",
    ">      Количество элементов в регуляризационнной группе выбирает эмперически. То есть это количество элементов, которым мы сглаживаем.    \n",
    ">      Смысл в том, что мы берем сколько-то элементов с занчением для всех категорий и сглаживаем им наши отдельные категории.    \n",
    ">    - Размер регуляризирующей группы обычно выбирают с помощью grid search, то есть берут цикл для размера этой группы и считают результат модели для каждого размера,  \n",
    ">    и потом выбирают тот размер, для которого результат лучше.    \n",
    ">    \n",
    ">`target_encoding_linear`  \n",
    ">`target_encoding_bayes`      \n",
    ">    \n",
    ">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.target_encoding_linear()\n",
    "my_module.target_encoding_bayes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Использование кластеризации для категоризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Можно понизить размерность до 3  \n",
    ">и построить 3 д график  \n",
    ">По этому графику посмотреть есть ли у нас возможные кластеры  \n",
    ">Если есть, то выделить их  \n",
    ">Причем для понижения размерности можно брать все столбцы, а можно только часть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обогощение таблиц"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Проверка соответствия:   \n",
    ">Если у нас в разных таблицах есть значения, которые дожны быть одинакоые,    \n",
    ">то нужно проверить, что значения в одном столбце соответствуют значениям в другом столбце. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['column_name1'].equals(df['column_name2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Обоготить данные можно следующими способами\n",
    "- взять поле нашей таблицы и найти дополнительные данные в интернете или ещё где-то и потом связать с нашей колонкой по этому полю  \n",
    ">Самое просто это дата, если у нас есть дата, то мы можем много разной доп информации внести в наши данные связывая по дате.  \n",
    ">Также, например, у нас есть какие-то коды чего-то, мы ищем информацию по этим кодам и находим табличку с доп инфой по этим кодам и можем обоготить ими   \n",
    ">нашу таблицу. Например, у нас города или страны, мы можем по ним также внести доп инфу из какого-то источника, которая нам поможет.  \n",
    ">Вообще любое поле нашей таблицы это потенцильная нить для обогощения. Главное понять с чем полезным мы можем соеденить  \n",
    ">через конкретное поле, чтобы получить больше полезной информации для анализа, по сути для детализации наших зависимостей или для поиска  \n",
    ">новых зависимостей и инсайтов в них.  \n",
    ">Процесс следующий - мы берем каждую колонку нашего дата сета и думаем, с чем через нее мы можем связать и если придумываем, то идешь ищем эту информацию и  \n",
    ">в итоге соединяем.  \n",
    "- Можно пойти от обратного. Сначал подумтаь какие данные нам могут помочь и поискать их в интернете например, а потом уже думать как их соеденить с нашими   \n",
    ">данными. Оба способа лучше делать одновременно.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Каждый раз, когда мы работаем с дата сетом, мы должны понять что является сущностью этого дата сета.  \n",
    ">Например событие, человек и прочее.  \n",
    ">Далее нам нужно поянть а можем ли мы его идентифицировать по текущим данным (не всегда есть уникальный ай ди).   \n",
    ">Если не можем, то нужно думта как обогатить данные, чтобы четко идентифицировать сущности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Что нужно обязательно првоерить после соединения\n",
    "- если мы соединяем по полю, которое уникально в обеих таблицах\n",
    ">    - количество строк в левом датафрейме равно количеству строк в итоговом\n",
    ">    - параметры каждого дата сета не изменились (если мы соединили правильно, то итоговые суммы по столбцам не должны измениться)\n",
    ">        - используем `df.sum(numeric_only=True)` для каждой таблицы до соединения и для общей таблицы и сравниваем значения\n",
    ">        - можно использвоать `df.describe` также до и после объединения и сравнивать параметры\n",
    "- если у нас в одной из колонок для соединения не уникальные значения (то есть для одной строки в левой таблице будет несколько в итоговй)    \n",
    ">    - Сначала группируем таблицы, чтобы поле для соединения в обеих таблицах было уникальное\n",
    ">    и применяем предыдущий шаг с количеством строк в левой и итоговой и суммой значений в левой и итоговой одинаковой\n",
    ">    - Если нам нужно соеденить без группировки (но это редко может быть, поэтому нужно подумать точно ли не моежм сгруппировать)  \n",
    ">    тогда нет выбора и остаются только следующие варианты  \n",
    ">        - если в левой таблице уникальные записи в колонке, по которйо соединяем    \n",
    ">            - тогда считаем сколько было записей в левой таблице в колонке для соединения и сравниваем с количеством **уникальных** записей в итоговой  \n",
    ">            они должны совпадать, но тут важно в итоговой брать уникальные записи\n",
    ">        - есил и в левой и правой нет уникальных\n",
    ">            - тут считаем сколько **уникальных** в левой до и сколько **уникальных** в итоговой, должно совпадать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если у нас что-то не сходится после соединения таблиц, то нужно внимально изучить это.  \n",
    ">Тут может быть инсайт (кто-то не правильно вносит информацию, какие-то значения неверные или кто-то что-то хотел спрятать, не указать и прчоее).  \n",
    ">Когда видим нестыковки после соединения таблиц, то должна загораться красная лампочка. Это потенциальный инсайт, баг, который мы можем найти и сообщить, чтобы его починили. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">помним, что метод соединения inner стоит по умолчанию в merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">В колонках, по которым будем соеднить, проверяем, нет ли пропусков, пропуски нужно заменить нулями.  \n",
    ">Иначе будет либо ошибка, либо пропуски сджойнятся с пропусками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Проблема справочников  \n",
    ">При объединение таблиц важно помнить про то, что в разных таблицах не только названия столбцов может быть разное,  \n",
    ">но и одно значение может быть записано по разному в разных таблицах, например, названия профессий, названия городов,  \n",
    ">имя в одной таблице на русском, а в другой на английском, номер телефона с черточкой или плюсом и без черточки или плюса.  \n",
    ">Поэтому не забываем привести все значения таблиц к нижнему регистру, чтобы не было проблем разными регистрами для одного слова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Проблема временных зон  \n",
    ">В одной таблице может быть выгрузка по местному времени, а в другом по московскому  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Проблема курсов валют  \n",
    ">Разыне системы могут брать курс за разные промежутки вермени, например, одна система берет курс в гугле (раз в час обновляется),  \n",
    ">а другая система берет курс в ЦБ (обновляется раз в сутки)  \n",
    ">И поэтому итоговые резултаты могут не состыковаться, поэтому, когда видим курсы валют, то нужно убедиться. что они взяты из одного испточника  \n",
    ">и за один промежуток времени  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Когда мы работаем с данными, нам важно четко идентифицировать клиентов, событие или другую сущность, с которой мы работаем.  \n",
    ">Иначе у нас будет шум, так как мы одного и того же клиента учтем более одного  раза."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Как можно обоготить данные, чтобы лучше идентифицировать сущности\n",
    "- Добавить для клиента email, телефон, устройство, 4 цифры карты и другое, что может помочь его идентифицировать  \n",
    ">    Это важно так как у клиента могут быть разные телефоны, устройства, карты, но все это вместе поможет его идентифицировать точнее\n",
    "- Добавить для события локацию, погоду, связанные событие, праздники, что поможет нам идентифицировать событие   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">пишем как обработали данные, например"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Удалили колонки с id образования и семейного статуса, так как нам для графиков лучше подойдут названия, а не id.\n",
    "- Колонка со стажем имеет совершенно некорректные данные. Чтобы не внести искажение в анализ, удалим эту колонку.\n",
    "- Удалили отрицательные значения в колонке с количеством детей, которые составляли 0,2% от общего количества записей в данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Расчет метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики продукта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">тут будут расчеты продуктовых метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Экономические метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">тут будут расчеты экономических метрик"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если расчет метрик является важным аспектом вашего исследования и требует подробного описания, то создание отдельной главы будет лучшим решением.  \n",
    ">Если в этом разделе будет немного расчетов, то можно сделать расчеты метрик разделом предобработки данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Расчитываем разные метрики на основе имеющихся данных и тех, которыми смогли обогатить данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Важно следить за количеством недель в году, если мы создаем столбец месяца.  \n",
    ">Проверять чтобы у нас не появлялась неделя дополнительная, из за того, что мы захватили предыдущий год"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Когортный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Не забывать про когортный анализ. Если у нас есть параметр, по которому мы можем наши данные разбить на когорты, то  \n",
    ">нужно разложить на когорты и посмотреть динамику по когортам.  \n",
    ">Когорты это например, пользователи пришедшие в одни день или месяц.  \n",
    ">Если мы объеденим пользователей в когорты и посмотрим динамику какого-то параметра по месяцам например, то увидим как изменяется.  \n",
    ">Тут также нужно помнить, что если значение например за 3 месяц больше значения за 4 месяц, то это ничего не значит само по себе.  \n",
    ">Так как мы имеем дело с выборкой, то нам нужно проверить статистически значимая это разница.  \n",
    ">Тут нам понядобятся стат тесты.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ корреляций между переменными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исследование корреляционных связей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Топ n значений одного столбца по значениям в другом\n",
    ">Сделать функцию, чтобы в столбцах, где бльше 20 уникльных значений посмотреть топ n значений по другой колонке.  \n",
    ">Например, топ 10 покупателей по сумме покупок и прочее.  \n",
    ">Идея в том, что если  в столбце до 20 уникальных значений, то мы проанализируем комбинации с другими стобцами на графиках.  \n",
    ">А вот если у нас столбец не числовой и в нем больше 20 уникальных значений, то на графике мы не сможем понять топ n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Изучаем топ n значений в категориальных столбцах датафрейма, где значений больше порогового, по значению в столбце value_column.  \n",
    ">Тут можно делать разные топы, использовать разные функции.  \n",
    ">Задача изучить то, что мы не сможем изучить на графиках из-за болшого количества занчений в категориальной переменной,  \n",
    ">поэтому мы берем топ n значений.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = my_module.top_n_values_gen()\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Чтобы сравнить метрики между собой мы можем\n",
    "- использовать корреляционный анализ (Пирсена, Спирмена, Кенделла)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">`heatmap_corr(df)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.my_module.heatmap_corr(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Использование регрессии и случайного леса для определения влияния переменных  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Коэффициенты регрессии позволяют оценить влияние каждой переменной на целевую переменную, учитывая влияние других переменных,  \n",
    ">в то время как важные компоненты в случайном лесе позволяют оценить важность каждой переменной для предсказания целевой переменной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Используем регрессиию "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Чтобы построить регрессию и посмотреть стат значимость и коэффициенты удобно использовать модуль statsmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">VIF означает Variance Inflation Factor (Фактор инфляции дисперсии). Это статистическая метрика,   \n",
    ">используемая для обнаружения мультиколлинеарности (сильной корреляции) между предикторами (фичами) в линейной регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Обычно, VIF интерпретируется следующим образом:\n",
    ">\n",
    "- VIF < 5: слабая мультиколлинеарность\n",
    "- 5 ≤ VIF < 10: умеренная мультиколлинеарность\n",
    "- VIF ≥ 10: сильная мультиколлинеарность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\n",
    ">Смотрим R2 (коэффициент детерминации)\n",
    "- использовать коэффициенты у регресси\n",
    ">Мы строим регрессию и смотрим, у каких метрик больше коэффициенты. Таким образом мы поймем какие метрики сильнее зависят с целевой.  \n",
    ">Важно, чтобы независимые переменные некоррелировали по отдельности и вместе (мультиколлиниарность).  \n",
    ">По отдельности смотрим матрицу корреляции.  \n",
    ">Чтобы определить коррелириуют ли вместе, береме независимые переменные,  \n",
    ">и перебираем их выбирая одну из них целевой и смотрим R2.  \n",
    ">Если R2 большой, то значит эта метрика (которая целевая на этом шаге) хорошо описывается другими и ее можно выбросить.\n",
    ">Также не забываем поправки на гетероскедостичность (HC0, HC1, HC2, HC3) в статпакетах.  \n",
    ">Нам нужно ответить на следующие вопросы\n",
    ">    - Влияет ли метрика на целевую?\n",
    ">    Оцениваем коэффициенты в уравнении регресси у каждой метрики.  \n",
    ">    - Как влияет метрика на целевую?\n",
    ">    Смотрим R2 (коэффициент детерминации). И определяем какая часть целевой переменной определяется независимыми метриками.  \n",
    ">    - Коэффициенты при метриках в уравнении статистически значим? При какаом уровне значимости?\n",
    ">    Смотрим в стат пакете p value для каждого коэффициента, что нам говорит значим ли этот коэффициент.  \n",
    ">    То есть мы не просто смотрим его абсолютное значение, а учитываем p value.   \n",
    ">    - Дайте содержательную интерпретацию коэффицентам?\n",
    ">    При увеличении метрики k на 1, целевая метрика увеличивается на $b_{k} * 1$\n",
    ">    То есть нужно перевести коэффициенты в реальное сравнение, насколько увелчисться целевая метрика при изменении определенной метрики на 1\n",
    ">    - Найдите 95 процентный доверительный интервал.\n",
    ">    В стат пакете смотрим значение и оно говорит, что если мы многократно повторим ноши вычисления с новыми данными, то 95 процентов наших  \n",
    ">    полученных коэффицентов будут лежать в этом диапазоне.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Строим модель и изучаем результат  \n",
    ">`linear_regression_with_vif`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.linear_regression_with_vif()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Испльзовать коэффициенты у классификацию    \n",
    ">Строим случайный лес какие метрики сильнее всего влияют на решения модели.   \n",
    ">`plot_feature_importances_classifier`   \n",
    ">`plot_feature_importances_regression`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Тут нужно подумать как использовать категориальные переменные тоже   \n",
    ">Нужно их перевести в one hot encoding или подобное, чтобы также проверить силу их влияния на целевую перменную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_for_axis = dict(\n",
    "    debt = 'долга'\n",
    "    , children = 'Кол-во детей'\n",
    "    , age = 'Возраст'\n",
    "    , total_income = 'Доход'\n",
    ")\n",
    "\n",
    "my_module.plot_feature_importances_classifier(df, target='debt', titles_for_axis=titles_for_axis)\n",
    "my_module.plot_feature_importances_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">На основе полученных данных формулируем гипотезы, которые будем проверять в блоке проверки гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> используем быблиотеку `shap`, чтобы определить метрики, которые лучше других помогают предсказывать целевую перемменную"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ взаимосвязей переменных на графиках"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Про размер графиков    \n",
    ">Стандартный размер графиков width=600, height=400  \n",
    ">Для более сложных графиков, когда  требуется больше места для отображения данных, можно использовать размеры width=800, height=600 или width=1000, height=800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Сравнивать количество элементов нужно в абсолютных и относительных величинах.  \n",
    ">Когда мы сравниваем только в абсолютных величинах, мы не учитываем размеры групп.  \n",
    ">В одной группе может быть элементов больше чем в другой и тогда сравнение будет не совсем точным.   \n",
    ">Если у нас 2 категориальные переменные, то мы можем сравнивать отностельные величины  \n",
    ">по одной переменной, а можем по другой.  \n",
    ">Это как сравнивать суммарный возраст в группах, это не дает полной картины и мы сравниваем средний возраст,  \n",
    ">чтобы размер группы не влиял.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">ВАЖНО\n",
    ">Анализ графиков и выводы для них должны полностью перекрывать постановку задачи и цель.  \n",
    ">Это значит, что если цель проанализировать зависимость наличия долга, то мы в идеале должны проанализировать  \n",
    ">влиянеие каждой переменной на наличие долга (числовой и категориальной)  \n",
    ">Кончено нужно проанализировать все возможные зависимости.  \n",
    ">Но все зависимости с переменной в постновке задачи мы обязаны проверить и дать выводы. И о наличии и об отсутствие.  \n",
    ">Важные выводы делаем не только о наличие интересных моментов, но и об отсутствие.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Сначала раздел графиков  \n",
    ">На основе графиков формируются гипотезы (например, у нас у мужчин зп больше)\n",
    ">И после раздела графиков идет раздел проверки гипотез. Тут мы првоеряем разные гипотезы новые и те, что увидели на графиках.  \n",
    ">Это правильная последовательность сначала изучили графики и потом на основе их сформировали гипоетзы\n",
    ">Перед разделом про графики идет раздел с корреляцией и поиском главных компонет случайного леса.  \n",
    ">Мы выбиарем переменную, для которой мы далее хотим посмотреть разыне зависимости и указываем ее целевой для сучайного леса  \n",
    ">И смотрим какие фичи сильнее влияют.  \n",
    ">И теперь можем построить графики с целевой перменно и этими главными фичами и в выводе можно указать про то что это важные компоненты случаного леса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">На основе полученных данных формулируем гипотезы, которые будем проверять в блоке проверки гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ временных зависимостей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Строим когортный анализ, если есть возможность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если у нас есть даты, то мы можем посмотреть не просто абсолютные значения на каждую дату какой-то метрики,  \n",
    ">а посмотреть относительные значения относительно предыдущего значения.  \n",
    ">Для этого нужно составить таблицу, в которой будет изменение в процентах относительно предыдущего значения.  \n",
    ">И затем визуализировать для каждой даты динамику этого показателя "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучение зависимостей между числовыми переменными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Изучаем scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_for_axis = dict(\n",
    "    # numeric column\n",
    "    children = 'Кол-во детей'\n",
    "    , age = 'Возраст'\n",
    "    , total_income = 'Доход'    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.pairplot(df, titles_for_axis=titles_for_axis, horizontal_spacing=0.12, height=400, width=1200, rows=1, cols=3).show(config=dict(displayModeBar=False, dpi=200), renderer=\"png\")\n",
    "# если нужно интерактивый график, то\n",
    "fig = my_module.pairplot(df, titles_for_axis=titles_for_axis, horizontal_spacing=0.12, height=800, width=800)    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df = px.data.iris()\n",
    "fig = px.density_contour(df, x=\"sepal_width\", y=\"sepal_length\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучение зависимостей между категориальными переменными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Строим матрицу тепловой карты для категориальных переменных и изучаем зависимости  \n",
    ">`categorical_heatmap_matrix_gen`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Посмотрим на распределение количества элементов между группами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Нужно подумать как отобразить не только процент от всего количества, но и пороцент в группе  \n",
    ">То есть у нас есть значение в ячейке, сумма всех, сумма по категории на оси x и сумма по категории на оси Y   \n",
    ">Вот нужно как-то отобразить процент от суммы, процент от одной категории и от другой категории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "12 (0.5% of total, 20% of row, 15% of col) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Можно сделать кнопки, чтобы можно было подсветку делать внури колонок и строк  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Можно сделать кнопки (процент от общего) (процент от тут указывается название оси x) (аналогично для второй оси)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_for_axis = dict(\n",
    "    # numeric column\n",
    "    children = ['Количество детей', 'количество детей', 0]\n",
    "    , age = ['Возраст, лет', 'возраст', 1]\n",
    "    , total_income = ['Ежемесячный доход', 'ежемесячный доход', 1]    \n",
    "     # category column\n",
    "    , education = ['Уровень образования', 'уровня образования']\n",
    "    , family_status = ['Семейное положение', 'семейного положения']\n",
    "    , gender = ['Пол', 'пола']\n",
    "    , income_type = ['Тип занятости', 'типа занятости']\n",
    "    , debt = ['Задолженность', 'задолженности']\n",
    "    , purpose = ['Цель получения кредита', 'цели получения кредита']\n",
    "    , has_child = ['Наличие детей', 'наличия детей']\n",
    "    , age_cat = ['Возрастная категория, лет', 'возрастной категории']\n",
    "    , total_income_cat = ['Категория дохода', 'категории дохода']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.categorical_graph_analys_gen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Строим treemap  \n",
    ">`treemap`   \n",
    ">`treemap_dash`   \n",
    ">```\n",
    ">app = treemap_dash(df)\n",
    ">if __name__ == '__main__':\n",
    ">    app.run_server(debug=True)\n",
    ">```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.treemap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = my_module.treemap_dash(df)\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Строим parallel_categories    \n",
    ">`parallel_categories `  \n",
    ">`parallel_categories_dash `  \n",
    ">```\n",
    ">app = treemap_dash(df)\n",
    ">if __name__ == '__main__':\n",
    ">    app.run_server(debug=True)\n",
    ">```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.parallel_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = my_module.parallel_categories_dash(df)\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Строим Sankey  \n",
    ">`sankey `   \n",
    ">`sankey_dash`\n",
    ">\n",
    ">```\n",
    ">app = treemap_dash(df)\n",
    ">if __name__ == '__main__':\n",
    ">    app.run_server(debug=True)\n",
    ">```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.sankey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = my_module.sankey_dash(df)\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучение зависимостей между числовыми и категориальными переменными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Можно добавить кнопку среднее и количество  \n",
    ">Чтобы можно было посмотртеть распределение по количеству, когда смотрить среднее.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">```graph_analysis```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = my_module.graph_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Когда выбрали нужные графики, то стоим их"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Чтобы автоматически генерировались подписи осей и заголовок графика, нужно заполшнить такой словарь.    \n",
    ">Первый элемент списка - это подпись оси  \n",
    ">Второй элемент списка - это как это название будет отображаться в заголовке графика  \n",
    ">Для числовых столбцов также указывается род, чтобы правильно выбрать (Середнее, средний, средняя) (0 - средний род, 1 - мужской род, 2 - женский род)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'Среднее / Медианное / Суммарное {numeric} в зависимости от {category} и {category}'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_for_axis = dict(\n",
    "    # numeric column (0 - средний род, 1 - мужской род, 2 - женский род) (Середнее образовние, средний доход, средняя температура) )\n",
    "    children = ['Количество детей', 'количество детей', 0]\n",
    "    , age = ['Возраст, лет', 'возраст', 1]\n",
    "    , total_income = ['Ежемесячный доход', 'ежемесячный доход', 1]    \n",
    "     # category column\n",
    "    , education = ['Уровень образования', 'уровня образования']\n",
    "    , family_status = ['Семейное положение', 'семейного положения']\n",
    "    , gender = ['Пол', 'пола']\n",
    "    , income_type = ['Тип занятости', 'типа занятости']\n",
    "    , debt = ['Задолженность (1 - имеется, 0 - нет)', 'задолженности']\n",
    "    , purpose = ['Цель получения кредита', 'цели получения кредита']\n",
    "    , dob_cat = ['Возрастная категория, лет', 'возрастной категории']\n",
    "    , total_income_cat = ['Категория дохода', 'категории дохода']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summory = []\n",
    "columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = my_module.graph_analysis_gen(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Сначала запускаем код через 1 ячейку `columns = next(gen)`,  \n",
    ">чтобы появлися график и в `colunns` появились текущие названия колонок  \n",
    ">Далее пишем наблюдения, если хотим сохранить график и выполняем ячейку ниже.  \n",
    ">Если сохранять не хотим, то просто выполняем дальше `columns = next(gen)`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summory.append(dict(\n",
    "    columns = columns\n",
    "    , observations =\n",
    "'''\n",
    "**Наблюдения:**  \n",
    "- 21\n",
    "- Размер больше\n",
    "- 1\n",
    "- Сильнее других\n",
    "- \n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">В `summory` находятся названия колонок и наблюдения для графиков, которые стоит построить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">ВАЖНО  \n",
    ">После построеня всех графиков и коппирования комментариев из summory  \n",
    ">Мы в предваретельном выводе после раздела графиков вставляем выводы из summory  \n",
    ">Чтобы их не собирать  вручную у каждого графика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_temp():\n",
    "    for item in summory:\n",
    "        colunns = item['columns']\n",
    "        observations = item['observations'] \n",
    "        print(observations)\n",
    "        yield colunns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = gen_temp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Наблюдения:**  \n",
      "- 21\n",
      "- Размер больше\n",
      "- 1\n",
      "- Сильнее других\n",
      "- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "colunns = next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Чтобы построить график без category- просто закоментируй  строку с category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(df = df\n",
    "    , x = colunns[1]\n",
    "    , y = colunns[0]\n",
    "    , category = colunns[2]\n",
    "    # , width = 800\n",
    "    # , orientation = 'h'\n",
    ")  \n",
    "my_module.bar(config, titles_for_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Наблюдения:**\n",
    "-  У мужчин средний доход выше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Наблюдения:**\n",
    "-  текст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Формулирование и провера гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формулирование гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">На основе проведенного анализа данных сформулирем следующие гипотезы:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Гипотеза 1: Нет зависимость между наличием детей и возвратом кредита в срок.  \n",
    ">Гипотеза 2: У мужчин средний доход выше  \n",
    ">Гипотеза 3: Цель получения кредита не зависит от среднего ежемесяченого доход  \n",
    ">Гипотеза 4: Средний доход по семейному статусу одинаковый, но у вдовцов отличается  \n",
    ">Гипотеза 5: У должников в среднем больше детей   \n",
    ">Гипотеза 6: У должников средний возраст ниже  \n",
    ">Гипотеза 7: Медианный доход у должников и не должников не  отличается  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Не забываем что гипотезы можно проверять и между 2 категориальными переменными.  \n",
    ">Проверять есть ли между ними зависимости.  \n",
    ">Также если мы на графиках определили, что есть между 2 категориальными перменными связь,  то тут можем это проверить"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Проверим сформулированные гипотезы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">_hypothesis_ **Гипотеза 1: Название гипотезы**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">H0: The two categorical variables are independent.    \n",
    ">H1: The two categorical variables are not independent (i.e., there is a significant association between them).    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Примеры гипотез\n",
    "- Есть ли зависимость между наличием детей и возвратом кредита в срок?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Это будет часто возникать когда у нас категориальная целевая переменная и другие категориальные переменные.  \n",
    ">И мы хотим проверить влияют ли категориальные переменные на целевую.  \n",
    ">Например у нас есть поле наличие долга (есть или нет)  \n",
    ">Вот тут мы можем провести тесты со всеми каетгориями на наличие зависимости с наличием долга.  \n",
    ">В идеале мы на графиках должны найти гипотезы и тут их проверить.  \n",
    ">Но если у нас целевая переменная, то мы можем сравнить ее со всеми категориями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.chi2_pearson()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Формируем словарь для подписей осей и названия гистограм "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_for_axis = dict(\n",
    "    # numeric column\n",
    "    children = ['Количество детей', 'количества детей']\n",
    "    , age = ['Возраст', 'возраста']\n",
    "    , total_income = ['Ежемесячный доход', 'ежемесячного дохода']    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Нулевая гипотеза должна быть направлена на отсутствие эффекта, а альтернативная гипотеза должна быть направлена на наличие эффекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Формулируем гипотезу через H0, H1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">H0: У мужчин средний доход не выше, чем у женщин  \n",
    ">H1: У мужчин средний доход выше, чем у женщин"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Смотрим распределение метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.histogram(df.total_income, titles_for_axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Делаем вывод о распределении.    \n",
    ">Выбираем критерий для проверки гипотезы.  \n",
    ">Определяем уровнь значимости. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Проводим тест  \n",
    ">ВАЖНО  \n",
    ">df в ttest_ind_df и подобных можно испльзовать только для 2 стороннего случая  \n",
    ">Для одностороннего нужно придумать как определять какая группа первая по порядку пойдет в тест,  \n",
    ">в зависимости от постановки гипотезы, так как альтернатива опредляется исходя из порядка аргументов в функции теста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если используем ттест или анову, то сначала проводим тест на проверку дисперсии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">H0: У должников и не должников дисперсия не отличается  \n",
    ">H1: У должников и не должников дисперсия отличается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.levene_df\n",
    "my_module.levene\n",
    "my_module.bartlett_df\n",
    "my_module.bartlett"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Выбираем критерий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.chi2_pearson\n",
    "my_module.ttest_ind_df\n",
    "my_module.ttest_ind\n",
    "my_module.mannwhitneyu_df\n",
    "my_module.mannwhitneyu\n",
    "my_module.proportion_ztest_1sample\n",
    "my_module.proportions_ztest_2sample\n",
    "my_module.proportions_ztest_column_2sample\n",
    "my_module.proportions_chi2\n",
    "my_module.proportions_chi2_column\n",
    "my_module.anova_oneway_df\n",
    "my_module.anova_oneway\n",
    "my_module.tukey_hsd_df\n",
    "my_module.anova_oneway_welch_df\n",
    "my_module.kruskal_df\n",
    "my_module.kruskal\n",
    "my_module.bootstrap_diff_2sample # важно, сохраняем fig и в следующей ячейке делаем fig.shwo(), иначе на google colab работает некорректно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Проводим тест"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Если отклоняем гипотезу, то строим доверитлеьный интервал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.confint_t_2samples\n",
    "my_module.confint_t_2samples_df\n",
    "my_module.confint_proportion_ztest_2sample\n",
    "my_module.confint_proportion_ztest_column_2sample\n",
    "my_module.confint_proportion_2sample_statsmodels\n",
    "my_module.confint_proportion_coluns_2sample_statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_for_axis = dict(\n",
    "    # numeric column\n",
    "    children = ['Количество детей', 'количества детей']\n",
    "    , age = ['Возраст', 'возраста']\n",
    "    , total_income = ['Ежемесячный доход', 'ежемесячного дохода']    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Проверим эти гипотезы  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Гипотеза 1: Нет зависимость между наличием детей и возвратом кредита в срок**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">H0: Наличие детей не влияет на возврат кредита в срок.  \n",
    ">H1: Наличие детей влияет на возврат кредита в срок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Так как у нас обе переменных категориальные, то воспользуемся критерием хи-квадрат Пирсона.  \n",
    ">Уровень значимости alpha выберем 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Хи-квадрат Пирсона\n",
      "alpha =  0.05\n",
      "p-value =  1.724356890544321e-05\n",
      "Отклоняем нулевую гипотезу, поскольку p-value меньше уровня значимости\n"
     ]
    }
   ],
   "source": [
    "my_module.chi2_pearson(df.has_child, df.debt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результат:**  \n",
    ">На уровне значимости 0.05 гипотеза, что наличие детей не влияет на возврат кредита в срок не подтвердилась."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Сделать опцию в бутстреп функции, чтобы строился только доверительный интервал"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Также сделать функцию для доверилеьных интервалов для мана уитни через   \n",
    ">the Hodges-Lehmann estimation, which provides a point estimate and a confidence interval for the difference in medians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "\n",
    "# Perform the Mann-Whitney U test and calculate the confidence interval\n",
    "mw_test = pg.mwu(x, y, tail='two-sided', confidence=0.95)\n",
    "\n",
    "# Print the results\n",
    "print(mw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Perform the Mann-Whitney U test\n",
    "u_stat, p_value = stats.mannwhitneyu(x, y, alternative='two-sided')\n",
    "\n",
    "# Calculate the Hodges-Lehmann estimation\n",
    "hl_est = np.median(np.array([x_i - y_j for x_i in x for y_j in y]))\n",
    "\n",
    "# Calculate the confidence interval\n",
    "ci = stats.t.interval(0.95, len(x) + len(y) - 2, loc=hl_est, scale=stats.sem(np.array([x_i - y_j for x_i in x for y_j in y])))\n",
    "\n",
    "# Print the results\n",
    "print('Hodges-Lehmann estimation:', hl_est)\n",
    "print('Confidence interval:', ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Подход следуюищй - мы до раздела проверка гипотез, когда изучаем данные (разделы пропусков, выбросов, дубликатов, зависиместей между перменными и графики),  \n",
    ">то мы делаем выводы и формируем наблюдеия.  \n",
    ">Вот эти наблюдения и выводы нужно проверить в проверке гипотез.  \n",
    ">И потом в основном выводе уже писать не просто, что у нас мужчин больше чем женьшин, а писать, что на уровен значисомти таком то у нас мужчина больше чем  \n",
    ">женщин с таким то доверительным интервалом.  \n",
    ">Таким образом выводы по вомзожности должны проходить через этап проверки гипотез, тогда эти выводы становятся более существенными.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Гипотезы появляются, когда мы задаем вопросы данным. Мы изучили данные, преобработали и теперь начинаем задавать вопросы.  \n",
    "- Выдвигаем гипотезу (заметили что-то необычное и хотим проверить), далее формулируем ее и далее проверяем.  \n",
    "- Не забываем формулировать гипотезы словами. Пишем что является гипотезой H0, а что гипотезой H1  \n",
    "- Формулируем все гипотезы, которые хотим проверить. Если будет 100 гипотез, то все 100 нужно сформулировать и потом проверить и сделать вывод.  \n",
    "- Гипотезы могут быть и простыми вопросами без гипотез H0 и H1, такие гипотезы мы проверяем графиками или анализируя таблицу.  \n",
    "- Восновном, когда мы собиаремся применить стат аппарат для проверки гипотезы, то мы должны записать ее через H0 и H1.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Алгоритм проверки статистических гипотез\n",
    ">\n",
    "- постановка задачи\n",
    ">    - Сформулировать, что мы хотим узнать о выборках с точки зрения бизнес задачи (равны ли средние доходы в группах)\n",
    ">    - перевод бизнес-вопроса на язык статистики: средний доход в группах - проверка равенства средних значений\n",
    "- формулировка гипотез\n",
    ">    - формулировка нулевой гипотезы - с т.зр. равенства стат прараметров оцениваемых выборок   \n",
    ">    (Н0: Средние траты клиентов по группе А равны средним тратам клинентов по группе В)\n",
    ">    - формулировка альтернативной гипотезы - с точки зрения неравенства параметров  \n",
    ">    (Н1: Средние траты клиентов по группе А не равны средним тратам клинентов по группе В)\n",
    "- выбор критерия alpha (почему 0.05 или 0.01)\n",
    ">    - цена ошибки первого рода (при большой цене ошибки - в мед исследованиях, потенциальном ущербе ) - значение может быть больше, например 0.1\n",
    ">    - в ежедневных бизнес задачах, обычно - 0.05\n",
    "- анализ распределения\n",
    ">    - визуальная оценка\n",
    ">    - следим за выбросами\n",
    ">    - проверка гипотез о типе распредеделения (например критерий Шапиро-Уилка)\n",
    ">    - если распределение не нормальное и размер выборки достаточный (больше 30-50 элементов)  \n",
    ">    может быть использован t-test именно для проверки гипотезы о равенстве средних.  \n",
    ">    Согласно ЦПТ (центральная предельная теорема) средние этих выборок будут распределены нормально. См. статью Зотова\n",
    "- выбор критерия\n",
    ">    - при оценке равенства средних T-test или Welch T-test (если есть сомнения, то лучше Уэлча)\n",
    ">        - при рвенстве дисперсий используем обычный т тест\n",
    ">        - если дисперсии в выборках разные, то используем т теста Уэлча\n",
    "- получение результата\n",
    ">    - расчет p-value\n",
    "- интерпретация p-value\n",
    ">    - сравнение p-value и alpha\n",
    ">    - если альфа > p-value - отвергаем нулевую гипотезу\n",
    ">    - если альфа < p-value - не можем отвергнуть нулевую гипотезу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Какая у нас задача\n",
    "- Исследовать взаимосвязь между 2 переменными\n",
    ">    - обе переменные наминативные\n",
    ">        - Хи-квадрат Пирсона (не чувствителен к гетероскедастичности) (нормальность не обязательна)\n",
    ">    - обе переменные количественные\n",
    ">        - Коэффициент корреляции Пирсона (параметрика) (чувствителен к выбросам) (только непрерывные переменные) \n",
    ">        - Коэффициент корреляции Спирмена (чувствителен к выбросам) / Кендалла (менее чувствителен к выбросам) (непараметрика) (непрерывные переменные и порядковые категориальные переменные)  \n",
    ">    - одна переменная номинативная (принимает 2 занчения), вторая количественная\n",
    ">        - значения\n",
    ">            - Т-критерий Стьюдента (параметрика) (желательно нормальность) (чувствителен к выбросам) (чувствителен к гетероскедастичности)\n",
    ">                - если дисперсии равны (тест левена, барлета) и количество в группах равно (тест на равенство пропорций), то используем обычный т тест (эта формула более точно даст результат для этого случая)\n",
    ">                - если дисперсии не равны (тест левена, барлета) или количество в группах не равно (тест на равенство пропорций), то используем тест Уэлча (эта формула использует больше неопределенности и лучше подходит для этого случая)\n",
    ">            - U-критерий Манна-Уитни (непараметрика) (нормальность не обязательна) (не чувствителен к гетероскедастичности)\n",
    ">            Если тестируемая фича полностью сдвигает выборку на некий коэффициент theta или масштабирует выборку на некий параметр theta (theta > 0),  \n",
    ">            то критерий Манна-Уитни применим\n",
    ">        - доли\n",
    ">            - Z тест для долей (параметрика) (желательно нормальность) (чувствителен к выбросам) (чувствителен к гетероскедастичности)\n",
    ">            - Chi-square тест для долей (непараметрика) (нормальность не обязательна) (не чувствителен к гетероскедастичности)\n",
    "- Исследовать взаимосвязь между несколькими переменными\n",
    ">    - Дисперсионный анализ (параметрика) (дисперсии в группах должны быть примерно равны) (желательно нормальность) (чувствителен к выбросам) (чувствителен к гетероскедастичности)\n",
    ">    - Welch's ANOVA (устройчив к разной дисперсии в группах) (требует более больших размеров групп для точных результатов) (желательно нормальность) (чувствителен к выбросам) (не чувствителен к гетероскедастичности)\n",
    ">    - Критерий Краскела-Уоллиса (непараметрика) (нормальность не обязательна) (не чувствителен к гетероскедастичности)\n",
    ">    - Тест Тьюки (если anova или Краскела-Уоллиса нашил различия) (дисперсии в группах должны быть примерно равны) (параметрика) (желательно нормальность) (чувствителен к выбросам) (чувствителен к гетероскедастичности)\n",
    "- Проверить на равенство дисперсий в группах перед anova\n",
    ">    - Levene's test (не требует нормальность) (менее чувствительный)\n",
    ">    - Bartlett's test (требует нормальность) (более чувствительный)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Отличная статья про доверительные интервалы для разных статистик  \n",
    ">https://habr.com/ru/articles/807051/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">В бутстрепе, если мы хотим сравнить две выборки, то нельзя смотреть  \n",
    ">где находится исходная разница средних в бутстрапированной выборке  \n",
    ">Так как мы берем бутстреп из наших выборок и впролне реально.что наша разность  \n",
    ">будет близка к с реднему бутстропированной выборки  \n",
    ">Поэтому p value нужно определять по месту нуля в бутстропированной выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Посмотрим p value для 0 (если различий нет, то разница должна быть 0)\n",
    ">Для этого посчитаем cdf для + и - среднего, чтобы получить 2 значения cdf\n",
    ">а теперь возьмем минимум и умножим на 2, так как альт гипотеза у нас.что\n",
    ">просто не равно 0, значит и справа и слева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Estimating the power of a non-parametric test using bootstrapping involves simulating the testing process multiple times to estimate the probability of rejecting the null hypothesis. Here's a general outline of the steps:\n",
    "\n",
    "**Specify the null and alternative hypotheses **: Define the null and alternative hypotheses for your test. For example, the null hypothesis might be that the two groups have the same distribution, and the alternative hypothesis might be that the two groups have different distributions.\n",
    "\n",
    "Generate simulated data: Generate simulated data that reflects the null hypothesis. For example, you could generate two groups of random data from the same distribution.\n",
    "\n",
    "Perform the Mann-Whitney U test: Perform the Mann-Whitney U test on the simulated data to obtain a p-value.\n",
    "\n",
    "Repeat steps 2-3 many times: Repeat steps 2-3 many times (e.g., 1000 times) to generate a distribution of p-values under the null hypothesis.\n",
    "\n",
    "Estimate the power: Estimate the power of the test by calculating the proportion of times the p-value is below a certain significance level (e.g., 0.05) when the alternative hypothesis is true. To do this, you'll need to generate simulated data that reflects the alternative hypothesis and repeat steps 2-4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Долги есть у людей с разным доходом. \n",
    "- У должников в среднем больше детей.\n",
    "- У должников среднее количество детей больше у женщин, а у не должников срднее количество детей больше у мужчин\n",
    "- У должников средний возраст немного ниже для всех категорий семейного положения.\n",
    "- Медианный доход у должников и не должников практически не отличается\n",
    "- Должники имеют ниже средний возраст как мужчины так и женщины. Ситуация сохраняется во всех группах дохода. \n",
    "- Цель получения кредита практически не зависит от среднего ежемесяченого дохода.\n",
    "- 92 % клиентов не имеют долга.\n",
    "- Люди от 30 до 50 лет имеют самый высокий средний доход.\n",
    "- Больше всего кредит берут на цели, связанные с недвижимостью, кроме людей в гражданском браке\n",
    "- Люди в гражданском браке чаще берут кредит на свадьбу\n",
    "- Женщины чаще возвращают кредит.\n",
    "- Анализ значимости признаков для модели случайного леса показал, что доход является самым значимым признаком для предсказания задолженности.\n",
    "- 58 % клиентов либо женаты, либо замужем. 19 % в гражданском браке. Можно сделать вывод что большинство в браке.  \n",
    "- Большинство клиентов женщины (66 процентов).\n",
    "- Только 5 процентов клиентов моложе 25 лет. Основная часть клиентов старше 30 лет.\n",
    "- Чем меньше количество детей, тем больше значений с высоким доходом.\n",
    "- Болшая часть женатых имеет доход 100-200 тыс\n",
    "- На всех уровнях образоания, кроме ученой степени, доход у мужчин выше.\n",
    "- У мужчин, которые в браке или были в браке, количество детей больше, чем у женщин в той же категории."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Аномалии и особенности в данных:**\n",
    "- В датафрейме есть строки дубликаты. 54 строки. Меньше 1 % от всего датафрейма.  \n",
    "- В столбце с количеством детей есть отрицательные значения. 47 штук. Меньше 1 процента от всего датафрейма. Также есть клиенты с 20 детьми. \n",
    "- Колонока общий трудовой стаж содержит 74 % отрицаетльных значений. А также максимальное количество дней стажа больше 400 тысяч дней, это больше 1000 лет.\n",
    "- В колонке возраста 101 нулевое значени.\n",
    "- Колонка дохода имеет слишком много знаков после запятой. \n",
    "- В колонке с образованием присутствуют одни и те же знчения с разными регистрами. При этом в колонке с id образования все впрорядке.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результаты предобработки данных:**\n",
    "- Удалили колонки с id образования и семейного статуса, так как нам для графиков лучше подойдут названия, а не id.\n",
    "- Колонка со стажем имеет совершенно некорректные данные. Чтобы не внести искажение в анализ, удалим эту колонку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Результаты проверки гипотез:**  \n",
    "- Гипотеза 1: У мужчин средний доход выше, чем у женщин  \n",
    "> **Результат:** На уровне значимости 0.05 гипотеза подтвердилась. \n",
    "- Гипотеза 2: Цель получения кредита практически не зависит от среднего ежемесячного дохода  \n",
    "> **Результат:** На уровне значимости 0.05 у нас нет оснований отвергнуть гипотезу.\n",
    "- Гипотеза 3: Средний доход по семейному статусу примерно одинаковый, но у вдовцов отличается  \n",
    "> **Результат:** На уровне значимости 0.05 гипотеза подтвердилась.\n",
    "- Гипотеза 4: У должников в среднем больше детей  \n",
    "> **Результат:** На уровне значимости 0.05 гипотеза подтвердилась.   \n",
    "- Гипотеза 5: У должников средний возраст ниже  \n",
    "> **Результат:** На уровне значимости 0.05 гипотеза подтвердилась. 95% доверительный интервал для разницы средних возрастов для должников и не должников равен (-inf, -2.74).  \n",
    "- Гипотеза 6: Медианный доход у должников и не должников не отличается  \n",
    "> **Результат:** На уровне значимости 0.05 нет оснований отвергнуть гипотезу. 95% доверительный интервал разницы между медианным доходом должников и не должников равен (-2648.05, 179.34).  \n",
    "- Гипотеза 7: Наличие детей не влияет на возврат кредита в срок  \n",
    "> **Результат:** На уровне значимости 0.05 гипотеза не подтвердилась."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Рекомендации:**\n",
    "- Добавить контроль данных, чтобы не дублировались значения с разными регистрами в колонке с образованием.\n",
    "- Добавить уникальный идентификатор клиента, чтобы избежать дублирования строк.\n",
    "- Добавить проверку на отрицательные значения и на слишком болшьшие значения в количестве детей при загрузке данных.\n",
    "- Выяснить откуда возникают отрицательные значения в трудовом стаже и добавить контроль ввода невалидных данных.\n",
    "- Выяснить причину нулевых значений в колонке возраста и добавить проверку на нулевые значения при загрузке данных.\n",
    "- Выяснить причину большого количества знаков после запятой в колонке дохода."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Что нужно сообщить в выводе\n",
    "- информацию о том, что удалось подтвердить гипотезы (тут пишем только те, которые удалось подтвердить)\n",
    "- всю информацию о датасете, которые важны. Дубликаты, которые несут практическую пользу и рекомендации по ним, пропуски также с рекомендациями  \n",
    ">и остальные моменты по данным и рекомендации. Тут важно указывать именно найденные аномалии, которые имеют практическую пользу, которые нужно исправить и прочее.  \n",
    ">Пишем, что были найдены выбросы, они были связаны возможно с тем то и тем то. \n",
    "- и в конце обязательно call to action \n",
    ">написать что необходимо сделать с этими результатами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Советы по оформлению общего выывод\n",
    "- не нужно вставлять таблицы и графики в вывод. \n",
    ">В выводе пишем словами самое важное и практически полезное, что мы получили, причем в порядке убывания важности.  \n",
    ">И когда мы пишем, что увидели то-то, то приводим гиперссылку на график или результат ячейки, где это получено.  \n",
    ">Так будет компактный вывод и при необходимости человек сможет быстро перейти и посмотреть график или таблицу  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Удалось подтвердить гипотезу** о влиянии различных характеристик клиента на факт погашения кредита в срок. Каждый из рассмотренных параметров оказывает влияние на надёжность заёмщика. Рассмотренные факторы по-разному влияют на надёжность заёмщиков. Например, семейное положение оказалось более значимым фактором, чем уровень дохода.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-penny",
   "metadata": {},
   "source": [
    "- В ходе анализа исходного набора данных было проведено (были устранены пропуски в двух колонках с числовыми значениями - 'total_income' и 'days_employed').  \n",
    "- После __устранения явных и скрытых дупликатов__ и удаления оставшихся после обогащения пропусков объем датасета сократился на 0.05%\n",
    "- Были устранены __выбросы__ в колонках 'days_employed' и 'children': в первом случае выбросы возникли в результате системной ошибки (данные были внесены в часах, а не в днях); во втором случае ошибка, вероятнее всего была допущена людьми, вносившими данные в систему\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-strand",
   "metadata": {},
   "source": [
    "**Необходимо**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-worker",
   "metadata": {},
   "source": [
    ">1. Запросить в отделе по работе с клиентами информацию о возможности брать кредит без подтверждения дохода. \n",
    ">\n",
    ">2. Сообщить коллегам, занимающимся выгрузкой о наличие дубликатов, если вопрос не разрешится, запросить индентификационный номер клиента к датасету.\n",
    ">\n",
    ">3. Прописать в задаче на поставку данных формат данных (пол только F и M, положительные значения). Приложить информацию о найденных аномалиях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сначала проверяем орфографические ошибки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.correct_notebook_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Затем создаем номера у глав и оглавление**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Чтобы добавить номера глав и ссылки для оглавления и сделать оглавлнеие  \n",
    ">оглавление добавиться в начало ноутбука"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Сначала можно в режиме `draft` сделать пробный варант, проверить и потом уже запустить в режиме `final`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.make_headers_link_and_toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Далее создаем ссыки на выводы и аномалии**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Чтобы было удобно искать где вставить якорь для ссылки, названия выводов и аномалий должно точно совпадать   \n",
    ">в итоговом списке аномалий и выводов и в тех местах (то есть в наблюдениях под ячейками), куда мы будем помещать ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Чтобы сделать ссылки на выводы и аномалии, нужно  \n",
    ">в тех местах, куда хотим переходить по ссылке вставить текст выводов или аномалий (берем прямо из основных выводов)  \n",
    ">выводы должны начинаться с `_conclusion_`  \n",
    ">аномалии  должны начинаться с `_anomaly_`  \n",
    ">Примеры:  \n",
    ">    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_anomalies_ В столбце с количеством детей есть отрицательные значения. 47 штук. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Можно в одной ячейке и выводы и аномалии, с обеих ссылок будет переходить сюда, но назад будет возвращаться только в одно место,    \n",
    ">в то, которое было первым в ячейке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_conclusion_ Только 5 процентов клиентов моложе 25 лет. Основная часть клиентов старше 30 лет.\n",
    "_anomalies_ В колонке возраста 101 нулевое значени."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Содеражние выводов и аномалий появится в начале ноутбука  \n",
    ">также 2 режима `draft` и `final`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Подумать как сделать удобнее создание выводов  \n",
    ">Пока лучше сначала взять выводы из наблюдений и выбрать из них  наиболее важные и интересные, не меняя их.  \n",
    ">Далее берем этот список и поиском находим ячейку с этим выводом и перед графиком помещаем  \n",
    ">_conclusion_ и сам вывод  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Чтобы был нужный порядок в списке выводов и аномалий в начале отчета, нужно передвать словарь со списками выводов и аномалий.  \n",
    ">Переменная order принимает словарь, где ключи `onclusions` и `anomalies`, а значения это соответствующие списки  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Примеры списков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = dict(\n",
    "            conclusions =[ 'Женщины чаще возвращают кредит, чем мужчины.']\n",
    "            , anomalies = ['В датафрейме есть строки дубликаты. 54 строки. Меньше 1 % от всего датафрейма.  ']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.add_conclusions_and_anomalies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Если сильно нужно, создаем ссыки на гипотезы**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">В главе гипотез для каждой гипоетзы, куда будем переходить из оглавления, в начале перед гипотезой ставим _hypothesis_ и пробел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_hypothesis_ **Гипотеза 1: Название гипотезы**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Выполняем следующую функцию и в начале отчета появится список гипотез с ссылками  \n",
    ">Далее нужно добавить результат гипотез вручную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_module.add_hypotheses_links_and_toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Финальное размещение ноутбука на git hub с ссылкой на google colab**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Комитим на гит хаб финальную версию ноутбука.  \n",
    ">Создаем на гит хаб readme файл проекта, в котором в начале идет ссылка на google colab  \n",
    ">Далее ее открываем и переходим на google colab  \n",
    ">Выполняем все ячейки, смотрим все ли правильно отобразилось.  \n",
    ">Далее в меню File выбираем сохранить копию на гит хаб.  \n",
    ">Не меняем имя, тогда все содержимое ноутбука сохраниться на гит хаб.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "fbe58ca63fe33f9eeae9e71d10368d2b4a57f2b1b395836210cc60d362c66949"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
